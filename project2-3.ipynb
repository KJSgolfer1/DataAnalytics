{"cells":[{"cell_type":"markdown","metadata":{"id":"YAo_Hbv6yzvP"},"source":["Identifying License Plates\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0ghNiwgTA-W"},"outputs":[],"source":["\n","import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","import cv2\n","import os\n","import numpy as np\n","from imutils import paths\n","from random import randint\n","\n","# import the necessary packages\n","from sklearn.preprocessing import LabelBinarizer\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.layers import add\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.regularizers import l1_l2\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.utils import to_categorical\n","\n","from tensorflow.keras.layers import InputLayer\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WB1_s4rrzJVb"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T90S4pAeTDkV"},"outputs":[],"source":["\n","# image preprocessor\n","class SimpleImagePreprocessor:\n","    def __init__(self, width, height, cWidth = 0, cHeight = 0, cropAugment = 1, interpolation = cv2.INTER_AREA):\n","        # store target image width, height, and interpolation method for resizing\n","        self.width = width\n","        self.height = height\n","        self.cWidth = cWidth\n","        self.cHeight = cHeight\n","        self.interpolation = interpolation\n","        self.cropAugment = cropAugment\n","        self.translationAugment = 0\n","        \n","    def resize(self, image):\n","        # resize to a fixed size ignoring aspect ratio\n","        return [cv2.resize(image, (self.width, self.height), interpolation = self.interpolation)]\n","    \n","    # randomly crop an image nAugment times and return each\n","    def randomCrop(self, image):\n","        images = []\n","        \n","        image = image[0]\n","        \n","        # iterate from 0 to nAugment\n","        for counter in np.arange(0, self.cropAugment):\n","            # choose a random coordinates for the lower left corner of the image\n","            lowerLeftX = randint(0, self.width - self.cWidth)\n","            lowerLeftY = randint(0, self.height - self.cHeight)\n","            \n","            # crop the image from the random point to the specified size and append to a list of images\n","            images.append(image[lowerLeftY:lowerLeftY + self.cHeight, lowerLeftX:lowerLeftX + self.cWidth])\n","            \n","        # return the randomly cropped images\n","        return images\n","    \n","    def translate(self, image, pixels = 2):        \n","        # translate left, right, up, and down\n","        leftImage = np.roll(image, pixels)\n","        rightImage = np.roll(image, -pixels)\n","        upImage = np.roll(image, pixels, axis = 0)\n","        downImage = np.roll(image, -pixels, axis = 0)\n","        \n","        images = [image, leftImage, rightImage, upImage, downImage]\n","                \n","        # return images translated in each direction\n","        return images\n","        \n","# image dataset loader\n","class SimpleImageDatasetLoader:\n","    def __init__(self, cropAugment = 1, preprocessors = None):\n","        self.cropAugment = cropAugment\n","        self.translationAugment = 0\n","        \n","        # store the image preprocessor\n","        self.preprocessors = preprocessors\n","        \n","        # if there are no preprocessors, initialize as an empty list\n","        if self.preprocessors is None:\n","            self.preprocessors = []\n","            \n","        # if preprocessor.translate in self.preprocessors:\n","        #     self.translationAugment = 4\n","            \n","    def load(self, imagePaths, verbose = -1, bw = 0):\n","        # initialize the list of features and labels\n","        data = []\n","        labels = []\n","        \n","        \n","        # loop over the input images\n","        for (i, imagePath) in enumerate(imagePaths):\n","            # load an image and extract the class label from the path\n","            if bw == 1:\n","                image = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n","            else:\n","                image = cv2.imread(imagePath)\n","            \n","            # if there are image preprocessors, apply them to the image\n","            if self.preprocessors is not None:\n","                \n","                # loop over the preprocessors\n","                for p in self.preprocessors:                    \n","                    # apply the preprocessor\n","                    image = p(image)\n","            \n","            #print(imagePath)\n","            label = imagePath.split(os.path.sep)[-2]\n","            label = (self.cropAugment + self.translationAugment) * [label]\n","            \n","            # save the data and labels\n","            data.extend(image)\n","            labels.extend(label)\n","                        \n","            # give some updates on the preprocessing\n","            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n","                print('[INFO] processed {}/{}'.format(i + 1, len(imagePaths)))\n","                \n","        # return the data and labels in numpy arrays\n","        return (np.array(data), np.array(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97177,"status":"ok","timestamp":1637021342215,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"fkV_YXKQTE0j","outputId":"dc84796a-e2b7-46a4-c159-bdf07707dd25"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] processed 100/2193\n","[INFO] processed 200/2193\n","[INFO] processed 300/2193\n","[INFO] processed 400/2193\n","[INFO] processed 500/2193\n","[INFO] processed 600/2193\n","[INFO] processed 700/2193\n","[INFO] processed 800/2193\n","[INFO] processed 900/2193\n","[INFO] processed 1000/2193\n","[INFO] processed 1100/2193\n","[INFO] processed 1200/2193\n","[INFO] processed 1300/2193\n","[INFO] processed 1400/2193\n","[INFO] processed 1500/2193\n","[INFO] processed 1600/2193\n","[INFO] processed 1700/2193\n","[INFO] processed 1800/2193\n","[INFO] processed 1900/2193\n","[INFO] processed 2000/2193\n","[INFO] processed 2100/2193\n"]}],"source":["\n","path = 'archive43'\n","\n","imagePaths = list(paths.list_images(path))\n","\n","# chose the size for the image\n","preprocessor5 = SimpleImagePreprocessor(64, 64)\n","\n","# initialize the data loader\n","dataLoader = SimpleImageDatasetLoader(1, preprocessors = [preprocessor5.resize])\n","\n","# load the data into lists\n","trainX, trainY = dataLoader.load(imagePaths, verbose = 100)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1637021343704,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"SZiyR_kdl8Fp","outputId":"3da0d3d2-c639-4b28-affd-569cd41428ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["2193\n"]}],"source":["labels = trainY\n","pictures = trainX"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ae4lVO3jbcSV"},"outputs":[],"source":["trainY = labels\n","trainX = pictures"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1637021344482,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"xolMy4CrTEyT","outputId":"3ab6925a-1492-4f83-d376-5aaffccddd14"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'Alabama': 0, 'Alaska': 1, 'Arizona': 2, 'Arkansas': 3, 'California': 4, 'Colorado': 5, 'Connecticut': 6, 'Delaware': 7, 'Florida': 8, 'Georgia': 9, 'Hawaii': 10, 'Idaho': 11, 'Illinois': 12, 'Indiana': 13, 'Iowa': 14, 'Kansas': 15, 'Kentucky': 16, 'Louisiana': 17, 'Maine': 18, 'Maryland': 19, 'Massachusetts': 20, 'Michigan': 21, 'Minnesota': 22, 'Mississippi': 23, 'Missouri': 24, 'Montana': 25, 'Nebraska': 26, 'Nevada': 27, 'NewHampshire': 28, 'NewJersey': 29, 'NewMexico': 30, 'NewYork': 31, 'NorthCarolina': 32, 'NorthDakota': 33, 'Ohio': 34, 'Oklahoma': 35, 'Oregon': 36, 'Pennsylvania': 37, 'RhodeIsland': 38, 'SouthCarolina': 39, 'SouthDakota': 40, 'Tennessee': 41, 'Texas': 42, 'Utah': 43, 'Vermont': 44, 'Virginia': 45, 'Washington': 46, 'WashingtonDC': 47, 'WestVirginia': 48, 'Wisconsin': 49, 'Wyoming': 50}\n","50\n","48\n","46\n","44\n","41\n","38\n","37\n","34\n","29\n","33\n"]}],"source":["statesf = open('states.txt', 'r')\n","temp = []\n","\n","\n","states = {}\n","counter = 0\n","for state in statesf:\n","    state = state.strip()\n","    states[state] = counter\n","    counter += 1\n","\n","print(states)\n","\n","for state in trainY:\n","    temp.append(states[state])\n","for i in range(0, 1000, 100):   \n","    print(temp[i])\n","statesf.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udT2EllRstLa"},"outputs":[],"source":["trainY = temp"]},{"cell_type":"markdown","metadata":{"id":"YPrpc2wIzjFs"},"source":["### Normalize trainX and set trainY to categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djREwk_ETEvV"},"outputs":[],"source":["trainX = trainX.astype('float32')/255.0\n","\n","trainY = to_categorical(trainY, 51)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1637021345936,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"j9WaiQ211Oen","outputId":"cf9b3c14-5d75-4544-80ac-581ad572b3dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2193, 64, 64, 3)\n"]}],"source":["print(trainX.shape)"]},{"cell_type":"markdown","metadata":{"id":"xU8idmJ-zylg"},"source":["### Making sure each state has the same amount of images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":191,"status":"ok","timestamp":1637021346792,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"mIQDW7qtqyib","outputId":"1b438544-eccf-45d2-c591-ca1cec4d590d"},"outputs":[{"name":"stdout","output_type":"stream","text":["43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n","43\n"]}],"source":["folder_amount = [[] for i in range(51)]\n","\n","for i, thing in enumerate(labels):\n","    folder_amount[states[thing]].append(trainX[i])\n","    \n","for i in range(51):\n","    print(len(folder_amount[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5H6smPPnJNP"},"outputs":[],"source":["defaultX = trainX\n","defaultY = trainY\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_BO9YBHqHVk"},"outputs":[],"source":["trainX = defaultX\n","trainY = defaultY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtGNt-dNqD-4"},"outputs":[],"source":["trainX, testX, trainY, testY = train_test_split(trainX, trainY, test_size = .2)"]},{"cell_type":"markdown","metadata":{"id":"Edj83FIVfoko"},"source":["## LeNetReg Relu\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfA6al2TTEqG"},"outputs":[],"source":["class LeNetReg:\n","    # create the architecture\n","    def build(height, width, depth, classes, lam1 = 0, lam2 = 0, dropout = [0, 0, 0, 0.5]):\n","        # create a feedforward neural net\n","        model = Sequential()\n","\n","        # add a convolutional layer with 20 5x5 filters and a 2x2 max pooling layer\n","        model.add(Conv2D(32, (5, 5), padding = 'same', input_shape = (height, width, depth),\n","                         kernel_regularizer = l1_l2(l1 = lam1, l2 = lam2)))\n","        model.add(Activation('relu'))\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(dropout[0]))\n","        \n","        # add another convolutional layer with 50 5x5 filters and a 2x2 max pooling layer\n","        model.add(Conv2D(64, (5, 5), padding= 'same', kernel_regularizer = l1_l2(l1 = lam1, l2 = lam2)))\n","        model.add(Activation('relu'))\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(dropout[1]))\n","        \n","        # add another convolutional layer\n","        model.add(Conv2D(128, (5, 5), padding = 'same', kernel_regularizer = l1_l2(l1 = lam1, l2 = lam2)))\n","        model.add(Activation('relu'))\n","        model.add(Dropout(dropout[2]))\n","        \n","        # add a fully-connected layer\n","        model.add(Flatten())\n","        model.add(Dense(500))\n","        model.add(Activation('relu'))\n","        \n","        model.add(Dropout(dropout[3]))\n","        \n","        # add a softmax classifier\n","        model.add(Dense(classes))\n","        model.add(Activation('softmax'))\n","        \n","        # return the constructed model\n","        return model"]},{"cell_type":"markdown","metadata":{"id":"9vnoCM90fJjI"},"source":["### Baseline Model for LeNegReg model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215164,"status":"ok","timestamp":1637012861419,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"uF1N9OxcNT7D","outputId":"a5c85753-3926-4598-942b-0130f1447140"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","116/116 [==============================] - 4s 32ms/step - loss: 3.9355 - accuracy: 0.0247\n","Epoch 2/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.9226 - accuracy: 0.0288\n","Epoch 3/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.9037 - accuracy: 0.0357\n","Epoch 4/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.8797 - accuracy: 0.0449\n","Epoch 5/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.8604 - accuracy: 0.0431\n","Epoch 6/50\n","116/116 [==============================] - 4s 30ms/step - loss: 3.8349 - accuracy: 0.0610\n","Epoch 7/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.8077 - accuracy: 0.0725\n","Epoch 8/50\n","116/116 [==============================] - 4s 30ms/step - loss: 3.7736 - accuracy: 0.0840\n","Epoch 9/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.7218 - accuracy: 0.0966\n","Epoch 10/50\n","116/116 [==============================] - 4s 30ms/step - loss: 3.6734 - accuracy: 0.1116\n","Epoch 11/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.6049 - accuracy: 0.1242\n","Epoch 12/50\n","116/116 [==============================] - 4s 30ms/step - loss: 3.5209 - accuracy: 0.1461\n","Epoch 13/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.4232 - accuracy: 0.1650\n","Epoch 14/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.3398 - accuracy: 0.1949\n","Epoch 15/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.2361 - accuracy: 0.2174\n","Epoch 16/50\n","116/116 [==============================] - 4s 31ms/step - loss: 3.1422 - accuracy: 0.2352\n","Epoch 17/50\n","116/116 [==============================] - 3s 30ms/step - loss: 3.0015 - accuracy: 0.2576\n","Epoch 18/50\n","116/116 [==============================] - 4s 30ms/step - loss: 2.9163 - accuracy: 0.2770\n","Epoch 19/50\n","116/116 [==============================] - 4s 30ms/step - loss: 2.8185 - accuracy: 0.2984\n","Epoch 20/50\n","116/116 [==============================] - 4s 31ms/step - loss: 2.6767 - accuracy: 0.3416\n","Epoch 21/50\n","116/116 [==============================] - 4s 30ms/step - loss: 2.5864 - accuracy: 0.3410\n","Epoch 22/50\n","116/116 [==============================] - 4s 31ms/step - loss: 2.4565 - accuracy: 0.3818\n","Epoch 23/50\n","116/116 [==============================] - 4s 31ms/step - loss: 2.3417 - accuracy: 0.3985\n","Epoch 24/50\n","116/116 [==============================] - 4s 30ms/step - loss: 2.2229 - accuracy: 0.4227\n","Epoch 25/50\n","116/116 [==============================] - 3s 30ms/step - loss: 2.0868 - accuracy: 0.4491\n","Epoch 26/50\n","116/116 [==============================] - 4s 30ms/step - loss: 1.9433 - accuracy: 0.4894\n","Epoch 27/50\n","116/116 [==============================] - 4s 30ms/step - loss: 1.8616 - accuracy: 0.5129\n","Epoch 28/50\n","116/116 [==============================] - 4s 31ms/step - loss: 1.7243 - accuracy: 0.5451\n","Epoch 29/50\n","116/116 [==============================] - 4s 31ms/step - loss: 1.6187 - accuracy: 0.5814\n","Epoch 30/50\n","116/116 [==============================] - 4s 32ms/step - loss: 1.4949 - accuracy: 0.5975\n","Epoch 31/50\n","116/116 [==============================] - 4s 31ms/step - loss: 1.4130 - accuracy: 0.6216\n","Epoch 32/50\n","116/116 [==============================] - 4s 31ms/step - loss: 1.2758 - accuracy: 0.6492\n","Epoch 33/50\n","116/116 [==============================] - 4s 30ms/step - loss: 1.1718 - accuracy: 0.6809\n","Epoch 34/50\n","116/116 [==============================] - 4s 30ms/step - loss: 1.0979 - accuracy: 0.6929\n","Epoch 35/50\n","116/116 [==============================] - 4s 30ms/step - loss: 1.0696 - accuracy: 0.7142\n","Epoch 36/50\n","116/116 [==============================] - 4s 31ms/step - loss: 0.9435 - accuracy: 0.7487\n","Epoch 37/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.8779 - accuracy: 0.7556\n","Epoch 38/50\n","116/116 [==============================] - 4s 31ms/step - loss: 0.8623 - accuracy: 0.7642\n","Epoch 39/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.7128 - accuracy: 0.8091\n","Epoch 40/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.7112 - accuracy: 0.8068\n","Epoch 41/50\n","116/116 [==============================] - 3s 30ms/step - loss: 0.6921 - accuracy: 0.8051\n","Epoch 42/50\n","116/116 [==============================] - 3s 30ms/step - loss: 0.6356 - accuracy: 0.8212\n","Epoch 43/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.5293 - accuracy: 0.8476\n","Epoch 44/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.4991 - accuracy: 0.8614\n","Epoch 45/50\n","116/116 [==============================] - 4s 31ms/step - loss: 0.5175 - accuracy: 0.8574\n","Epoch 46/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.4390 - accuracy: 0.8792\n","Epoch 47/50\n","116/116 [==============================] - 4s 31ms/step - loss: 0.4967 - accuracy: 0.8614\n","Epoch 48/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.3728 - accuracy: 0.8884\n","Epoch 49/50\n","116/116 [==============================] - 4s 30ms/step - loss: 0.3878 - accuracy: 0.8936\n","Epoch 50/50\n","116/116 [==============================] - 4s 31ms/step - loss: 0.3558 - accuracy: 0.8942\n"]}],"source":["shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51)\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.01), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 15\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"nW6ayslBfkI2"},"source":["### Getting a starting L1 and L2 for our LeNetReg model with relu activation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1529663,"status":"ok","timestamp":1637014624560,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"RXkcGKpJduM5","outputId":"a8774cb2-3c3e-401a-f86f-597252ed609e"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 1s 10ms/step - loss: 1.2449 - accuracy: 0.7047\n","Dev accuracy for l1 = 0 , l2 = 0 is 0.704675018787384\n","55/55 [==============================] - 1s 12ms/step - loss: 3.9285 - accuracy: 0.0234\n","Dev accuracy for l1 = 0 , l2 = 0.1 is 0.023375142365694046\n","55/55 [==============================] - 1s 12ms/step - loss: 3.9284 - accuracy: 0.0234\n","Dev accuracy for l1 = 0 , l2 = 1 is 0.023375142365694046\n","55/55 [==============================] - 1s 10ms/step - loss: 3.9285 - accuracy: 0.0234\n","Dev accuracy for l1 = 0 , l2 = 5 is 0.023375142365694046\n","55/55 [==============================] - 1s 12ms/step - loss: 7.1088 - accuracy: 0.0234\n","Dev accuracy for l1 = 0.1 , l2 = 0 is 0.023375142365694046\n","55/55 [==============================] - 1s 10ms/step - loss: 7.0120 - accuracy: 0.0234\n","Dev accuracy for l1 = 0.1 , l2 = 0.1 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 7.3234 - accuracy: 0.0234\n","Dev accuracy for l1 = 0.1 , l2 = 1 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 7.2999 - accuracy: 0.0234\n","Dev accuracy for l1 = 0.1 , l2 = 5 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 35.8579 - accuracy: 0.0234\n","Dev accuracy for l1 = 1 , l2 = 0 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 35.5038 - accuracy: 0.0234\n","Dev accuracy for l1 = 1 , l2 = 0.1 is 0.023375142365694046\n","55/55 [==============================] - 1s 10ms/step - loss: 34.9257 - accuracy: 0.0234\n","Dev accuracy for l1 = 1 , l2 = 1 is 0.023375142365694046\n","55/55 [==============================] - 1s 12ms/step - loss: 38.2085 - accuracy: 0.0234\n","Dev accuracy for l1 = 1 , l2 = 5 is 0.023375142365694046\n","55/55 [==============================] - 1s 10ms/step - loss: 163.9311 - accuracy: 0.0234\n","Dev accuracy for l1 = 5 , l2 = 0 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 164.2141 - accuracy: 0.0234\n","Dev accuracy for l1 = 5 , l2 = 0.1 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 160.3356 - accuracy: 0.0234\n","Dev accuracy for l1 = 5 , l2 = 1 is 0.023375142365694046\n","55/55 [==============================] - 1s 11ms/step - loss: 159.2681 - accuracy: 0.0234\n","Dev accuracy for l1 = 5 , l2 = 5 is 0.023375142365694046\n"]}],"source":["best_hyperparameters = [0, 0]\n","best_accuracy = 0\n","\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","maxIt = 20\n","batch_size_total = 20\n","\n","for l1 in [0, 0.1, 1, 5]:\n","    for l2 in [0, 0.1, 1, 5]:\n","\n","        model = LeNetReg.build(64, 64, 3, 51, l1, l2)\n","        model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","\n","\n","        H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 0)\n","        dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","\n","        print('Dev accuracy for l1 =', l1, ', l2 =', l2, 'is', dev_accuracy['accuracy'])\n","\n","        if dev_accuracy['accuracy'] > best_accuracy: \n","            best_hyperparameters = [l1, l2]\n","            best_accuracy = dev_accuracy['accuracy']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1637014624561,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"ZoB_CBeTi0ia","outputId":"4a89e4d5-b368-433f-f918-a2c92704e014"},"outputs":[{"data":{"text/plain":["[0, 0]"]},"execution_count":205,"metadata":{},"output_type":"execute_result"}],"source":["best_hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"SrJdTorIgSKP"},"source":["### Finding the starting dropout rate for our LeNetReg with relu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349747,"status":"ok","timestamp":1637015019889,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"pVH5cKYH64D7","outputId":"4807f74f-60ed-483f-ce1a-b4863f476f2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 1s 11ms/step - loss: 3.4130 - accuracy: 0.1454\n","Dev accuracy for dropout percentages [0.1, 0.1, 0.1, 0.5] is 0.14538198709487915\n","55/55 [==============================] - 1s 10ms/step - loss: 3.3450 - accuracy: 0.2286\n","Dev accuracy for dropout percentages [0.2, 0.2, 0.2, 0.5] is 0.22862029075622559\n","55/55 [==============================] - 1s 11ms/step - loss: 3.9284 - accuracy: 0.0234\n","Dev accuracy for dropout percentages [0.5, 0.5, 0.5, 0.5] is 0.023375142365694046\n","55/55 [==============================] - 1s 10ms/step - loss: 3.8774 - accuracy: 0.0485\n","Dev accuracy for dropout percentages [0.75, 0.75, 0.75, 0.75] is 0.04846066236495972\n"]}],"source":["tf.keras.backend.clear_session()\n","best_dropout = 0\n","best_accuracy = 0\n","batch_size_total = 20\n","for dropout in [[0.1, 0.1, 0.1, 0.5], [0.2, 0.2, 0.2, 0.5], [0.5, 0.5, 0.5, 0.5], [0.75, 0.75, 0.75, 0.75]]:\n","        \n","    model = LeNetReg.build(64, 64, 3, 51, best_hyperparameters[0], best_hyperparameters[1], dropout = dropout)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","\n","    maxIt = 20\n","    H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=0)\n","    dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","    print('Dev accuracy for dropout percentages', dropout, 'is', dev_accuracy['accuracy'])\n","    if dev_accuracy['accuracy'] > best_accuracy: \n","        best_dropout = dropout\n","        best_accuracy = dev_accuracy['accuracy']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1637015019889,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"LKAhXnw-JU0p","outputId":"abb53fcd-bdf6-49dd-fa17-64dc46e26eec"},"outputs":[{"data":{"text/plain":["[0.2, 0.2, 0.2, 0.5]"]},"execution_count":208,"metadata":{},"output_type":"execute_result"}],"source":["best_dropout"]},{"cell_type":"markdown","metadata":{"id":"koti06IngqOZ"},"source":["### Taking the best hyperparameters from the initial testing we trained a model for more iterations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212424,"status":"ok","timestamp":1637015232305,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"83cr3kAKJb0s","outputId":"05c2585b-4867-4601-dfe7-3095ea2b69f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 4s 36ms/step - loss: 3.9400 - accuracy: 0.0167\n","Epoch 2/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9317 - accuracy: 0.0208\n","Epoch 3/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9285 - accuracy: 0.0248\n","Epoch 4/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9237 - accuracy: 0.0294\n","Epoch 5/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9183 - accuracy: 0.0352\n","Epoch 6/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9111 - accuracy: 0.0311\n","Epoch 7/50\n","87/87 [==============================] - 3s 37ms/step - loss: 3.8905 - accuracy: 0.0340\n","Epoch 8/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.8670 - accuracy: 0.0433\n","Epoch 9/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.8588 - accuracy: 0.0542\n","Epoch 10/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.8329 - accuracy: 0.0513\n","Epoch 11/50\n","87/87 [==============================] - 3s 37ms/step - loss: 3.8252 - accuracy: 0.0698\n","Epoch 12/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.7938 - accuracy: 0.0767\n","Epoch 13/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.7504 - accuracy: 0.0802\n","Epoch 14/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.7280 - accuracy: 0.0917\n","Epoch 15/50\n","87/87 [==============================] - 3s 38ms/step - loss: 3.6845 - accuracy: 0.1073\n","Epoch 16/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.6350 - accuracy: 0.1182\n","Epoch 17/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.6247 - accuracy: 0.1246\n","Epoch 18/50\n","87/87 [==============================] - 3s 37ms/step - loss: 3.5704 - accuracy: 0.1205\n","Epoch 19/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.5183 - accuracy: 0.1344\n","Epoch 20/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.4614 - accuracy: 0.1499\n","Epoch 21/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.4091 - accuracy: 0.1742\n","Epoch 22/50\n","87/87 [==============================] - 3s 37ms/step - loss: 3.3513 - accuracy: 0.1753\n","Epoch 23/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.2996 - accuracy: 0.1880\n","Epoch 24/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.2248 - accuracy: 0.1972\n","Epoch 25/50\n","87/87 [==============================] - 3s 37ms/step - loss: 3.1617 - accuracy: 0.2238\n","Epoch 26/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.1149 - accuracy: 0.2313\n","Epoch 27/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.0423 - accuracy: 0.2486\n","Epoch 28/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.9769 - accuracy: 0.2705\n","Epoch 29/50\n","87/87 [==============================] - 3s 35ms/step - loss: 2.9324 - accuracy: 0.2670\n","Epoch 30/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.8344 - accuracy: 0.2907\n","Epoch 31/50\n","87/87 [==============================] - 3s 38ms/step - loss: 2.7727 - accuracy: 0.3045\n","Epoch 32/50\n","87/87 [==============================] - 3s 37ms/step - loss: 2.6824 - accuracy: 0.3126\n","Epoch 33/50\n","87/87 [==============================] - 3s 37ms/step - loss: 2.6231 - accuracy: 0.3420\n","Epoch 34/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.5534 - accuracy: 0.3437\n","Epoch 35/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.4362 - accuracy: 0.3731\n","Epoch 36/50\n","87/87 [==============================] - 3s 37ms/step - loss: 2.4214 - accuracy: 0.3702\n","Epoch 37/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.3303 - accuracy: 0.4123\n","Epoch 38/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.2797 - accuracy: 0.4158\n","Epoch 39/50\n","87/87 [==============================] - 3s 37ms/step - loss: 2.1711 - accuracy: 0.4279\n","Epoch 40/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.0734 - accuracy: 0.4631\n","Epoch 41/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.0445 - accuracy: 0.4591\n","Epoch 42/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.9744 - accuracy: 0.4631\n","Epoch 43/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.8580 - accuracy: 0.5150\n","Epoch 44/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.8142 - accuracy: 0.5104\n","Epoch 45/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7264 - accuracy: 0.5340\n","Epoch 46/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7139 - accuracy: 0.5392\n","Epoch 47/50\n","87/87 [==============================] - 3s 37ms/step - loss: 1.5880 - accuracy: 0.5698\n","Epoch 48/50\n","87/87 [==============================] - 3s 35ms/step - loss: 1.5670 - accuracy: 0.5634\n","Epoch 49/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.4985 - accuracy: 0.6055\n","Epoch 50/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.4301 - accuracy: 0.6090\n"]}],"source":["\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51, best_hyperparameters[0], best_hyperparameters[1], dropout=best_dropout)\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.01), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 20\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"ekZFdyXTmS5q"},"source":["### We took the best model from LeNetReg relu model and adjusted the 4th dropout to .2 to match the other three layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118405,"status":"ok","timestamp":1637030287196,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"z4QlzDDRiXeL","outputId":"ce86404f-8a69-4f6b-a433-14e55329f0d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 3s 24ms/step - loss: 3.9405 - accuracy: 0.0196\n","Epoch 2/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9277 - accuracy: 0.0271\n","Epoch 3/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9146 - accuracy: 0.0306\n","Epoch 4/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8966 - accuracy: 0.0340\n","Epoch 5/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.8617 - accuracy: 0.0404\n","Epoch 6/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.8495 - accuracy: 0.0421\n","Epoch 7/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8227 - accuracy: 0.0582\n","Epoch 8/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8008 - accuracy: 0.0709\n","Epoch 9/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.7663 - accuracy: 0.0692\n","Epoch 10/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.7271 - accuracy: 0.0905\n","Epoch 11/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.7064 - accuracy: 0.0940\n","Epoch 12/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.6463 - accuracy: 0.1136\n","Epoch 13/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.6094 - accuracy: 0.1234\n","Epoch 14/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.5533 - accuracy: 0.1401\n","Epoch 15/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.5036 - accuracy: 0.1407\n","Epoch 16/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.4271 - accuracy: 0.1649\n","Epoch 17/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.3501 - accuracy: 0.1736\n","Epoch 18/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.2588 - accuracy: 0.2036\n","Epoch 19/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.1574 - accuracy: 0.2116\n","Epoch 20/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.0781 - accuracy: 0.2313\n","Epoch 21/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.9919 - accuracy: 0.2543\n","Epoch 22/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.9040 - accuracy: 0.2757\n","Epoch 23/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.7953 - accuracy: 0.2958\n","Epoch 24/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.7005 - accuracy: 0.3310\n","Epoch 25/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.6101 - accuracy: 0.3351\n","Epoch 26/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.4727 - accuracy: 0.3812\n","Epoch 27/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.3867 - accuracy: 0.4046\n","Epoch 28/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.2578 - accuracy: 0.4066\n","Epoch 29/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.1343 - accuracy: 0.4481\n","Epoch 30/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.0259 - accuracy: 0.4544\n","Epoch 31/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.9183 - accuracy: 0.4925\n","Epoch 32/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.8235 - accuracy: 0.5173\n","Epoch 33/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.6842 - accuracy: 0.5507\n","Epoch 34/50\n","87/87 [==============================] - 2s 23ms/step - loss: 1.5641 - accuracy: 0.5877\n","Epoch 35/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.4345 - accuracy: 0.5992\n","Epoch 36/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.3832 - accuracy: 0.6223\n","Epoch 37/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.2686 - accuracy: 0.6430\n","Epoch 38/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1524 - accuracy: 0.6770\n","Epoch 39/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.0917 - accuracy: 0.7013\n","Epoch 40/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9710 - accuracy: 0.7249\n","Epoch 41/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9062 - accuracy: 0.7359\n","Epoch 42/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8638 - accuracy: 0.7607\n","Epoch 43/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.7322 - accuracy: 0.7947\n","Epoch 44/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.7150 - accuracy: 0.7935\n","Epoch 45/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.6639 - accuracy: 0.8085\n","Epoch 46/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.6403 - accuracy: 0.8120\n","Epoch 47/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.5777 - accuracy: 0.8333\n","Epoch 48/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.5276 - accuracy: 0.8460\n","Epoch 49/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.4644 - accuracy: 0.8633\n","Epoch 50/50\n","87/87 [==============================] - 2s 25ms/step - loss: 0.4206 - accuracy: 0.8818\n"]}],"source":["shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51, 0, 0, dropout=[0.2,0.2,0.2,0.2])\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.01), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 20\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"Zv8UK-Chmnpr"},"source":["### In this model we expiremented with changing the learning rate to .1 which is a bit more aggressive. We also decided to keep the 4th dropout at .2 as we saw greater accuracy in this model than the last."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116297,"status":"ok","timestamp":1637030493734,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"sulyvqsNml-O","outputId":"27729228-2822-4414-e529-a4d98699800f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 3s 24ms/step - loss: 3.9359 - accuracy: 0.0185\n","Epoch 2/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9339 - accuracy: 0.0202\n","Epoch 3/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.9293 - accuracy: 0.0225\n","Epoch 4/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9333 - accuracy: 0.0196\n","Epoch 5/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.9286 - accuracy: 0.0213\n","Epoch 6/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9336 - accuracy: 0.0271\n","Epoch 7/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.9253 - accuracy: 0.0271\n","Epoch 8/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9328 - accuracy: 0.0213\n","Epoch 9/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9169 - accuracy: 0.0311\n","Epoch 10/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8957 - accuracy: 0.0293\n","Epoch 11/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.9039 - accuracy: 0.0392\n","Epoch 12/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8505 - accuracy: 0.0433\n","Epoch 13/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8196 - accuracy: 0.0640\n","Epoch 14/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.7166 - accuracy: 0.0882\n","Epoch 15/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.6345 - accuracy: 0.1055\n","Epoch 16/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.5114 - accuracy: 0.1315\n","Epoch 17/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.3717 - accuracy: 0.1661\n","Epoch 18/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.2357 - accuracy: 0.1932\n","Epoch 19/50\n","87/87 [==============================] - 2s 25ms/step - loss: 3.0523 - accuracy: 0.2249\n","Epoch 20/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.9170 - accuracy: 0.2572\n","Epoch 21/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.7271 - accuracy: 0.3016\n","Epoch 22/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.5601 - accuracy: 0.3535\n","Epoch 23/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.4562 - accuracy: 0.3622\n","Epoch 24/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.2661 - accuracy: 0.4210\n","Epoch 25/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.1007 - accuracy: 0.4516\n","Epoch 26/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.0196 - accuracy: 0.4746\n","Epoch 27/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.9078 - accuracy: 0.5063\n","Epoch 28/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.7829 - accuracy: 0.5352\n","Epoch 29/50\n","87/87 [==============================] - 2s 25ms/step - loss: 1.7515 - accuracy: 0.5288\n","Epoch 30/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.6456 - accuracy: 0.5681\n","Epoch 31/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.5517 - accuracy: 0.5952\n","Epoch 32/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.4532 - accuracy: 0.6205\n","Epoch 33/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.4729 - accuracy: 0.6113\n","Epoch 34/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.2736 - accuracy: 0.6684\n","Epoch 35/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.2428 - accuracy: 0.6840\n","Epoch 36/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1595 - accuracy: 0.7042\n","Epoch 37/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1291 - accuracy: 0.7001\n","Epoch 38/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1333 - accuracy: 0.7134\n","Epoch 39/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1584 - accuracy: 0.7157\n","Epoch 40/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9784 - accuracy: 0.7514\n","Epoch 41/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.0111 - accuracy: 0.7364\n","Epoch 42/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9398 - accuracy: 0.7474\n","Epoch 43/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9380 - accuracy: 0.7486\n","Epoch 44/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9165 - accuracy: 0.7468\n","Epoch 45/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8498 - accuracy: 0.7809\n","Epoch 46/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8901 - accuracy: 0.7728\n","Epoch 47/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8895 - accuracy: 0.7659\n","Epoch 48/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.7934 - accuracy: 0.7814\n","Epoch 49/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8743 - accuracy: 0.7693\n","Epoch 50/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8176 - accuracy: 0.8010\n"]}],"source":["shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51, 0, 0, dropout=[0.2,0.2,0.2,0.2])\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.1), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 20\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"0IHqE3TQpGu_"},"source":["### .1 learning rate seemed to be a bit to high so we decided to scale it down some it .05"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119022,"status":"ok","timestamp":1637030995792,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"OdA3gg-qpA2i","outputId":"9b4bd6d3-d2f8-418f-f07e-43c6950256d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 3s 24ms/step - loss: 3.9355 - accuracy: 0.0219\n","Epoch 2/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.9106 - accuracy: 0.0311\n","Epoch 3/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.8789 - accuracy: 0.0525\n","Epoch 4/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8551 - accuracy: 0.0525\n","Epoch 5/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.8304 - accuracy: 0.0669\n","Epoch 6/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.7516 - accuracy: 0.0957\n","Epoch 7/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.6308 - accuracy: 0.1171\n","Epoch 8/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.5376 - accuracy: 0.1407\n","Epoch 9/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.5465 - accuracy: 0.1321\n","Epoch 10/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.3742 - accuracy: 0.1626\n","Epoch 11/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.2024 - accuracy: 0.2151\n","Epoch 12/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.0416 - accuracy: 0.2364\n","Epoch 13/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.8848 - accuracy: 0.2734\n","Epoch 14/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.7462 - accuracy: 0.2970\n","Epoch 15/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.5739 - accuracy: 0.3431\n","Epoch 16/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.4431 - accuracy: 0.3795\n","Epoch 17/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.2488 - accuracy: 0.4262\n","Epoch 18/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.1376 - accuracy: 0.4389\n","Epoch 19/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.9762 - accuracy: 0.4931\n","Epoch 20/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.7846 - accuracy: 0.5346\n","Epoch 21/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.6551 - accuracy: 0.5577\n","Epoch 22/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.6440 - accuracy: 0.5657\n","Epoch 23/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.4626 - accuracy: 0.6009\n","Epoch 24/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.3279 - accuracy: 0.6471\n","Epoch 25/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1564 - accuracy: 0.6805\n","Epoch 26/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.0870 - accuracy: 0.7088\n","Epoch 27/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.0634 - accuracy: 0.7128\n","Epoch 28/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9896 - accuracy: 0.7301\n","Epoch 29/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.8735 - accuracy: 0.7710\n","Epoch 30/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.7226 - accuracy: 0.7971\n","Epoch 31/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.6541 - accuracy: 0.8103\n","Epoch 32/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.7096 - accuracy: 0.8068\n","Epoch 33/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.6138 - accuracy: 0.8345\n","Epoch 34/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.5475 - accuracy: 0.8425\n","Epoch 35/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.4366 - accuracy: 0.8795\n","Epoch 36/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.5053 - accuracy: 0.8674\n","Epoch 37/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.4195 - accuracy: 0.8864\n","Epoch 38/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.3126 - accuracy: 0.9193\n","Epoch 39/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.4279 - accuracy: 0.8864\n","Epoch 40/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2971 - accuracy: 0.9106\n","Epoch 41/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.3610 - accuracy: 0.9031\n","Epoch 42/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.2829 - accuracy: 0.9250\n","Epoch 43/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.3282 - accuracy: 0.9141\n","Epoch 44/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2766 - accuracy: 0.9262\n","Epoch 45/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2335 - accuracy: 0.9371\n","Epoch 46/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2371 - accuracy: 0.9354\n","Epoch 47/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2809 - accuracy: 0.9291\n","Epoch 48/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2596 - accuracy: 0.9331\n","Epoch 49/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.2341 - accuracy: 0.9394\n","Epoch 50/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.2077 - accuracy: 0.9523\n"]}],"source":["shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51, 0, 0, dropout=[0.2,0.2,0.2,0.2])\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.05), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 20\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1637015233124,"user":{"displayName":"Nicholas Velasquez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghh-0R7ai7YRQraegvB_VnXX_J-Ca97O8v0SymfKA=s64","userId":"06249087465000726097"},"user_tz":300},"id":"YAm_r2Vxmz6e","outputId":"b0126a9d-b743-46ce-b5ad-bc9968073ce6"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 1s 11ms/step - loss: 0.6085 - accuracy: 0.8569\n"]},{"data":{"text/plain":["{'accuracy': 0.8568985462188721, 'loss': 0.6085496544837952}"]},"execution_count":210,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(x = trainX, y = trainY, return_dict = 1)"]},{"cell_type":"markdown","metadata":{"id":"8l4fLtiK6Jug"},"source":["## LeNetReg Elu\n","### Baseline model for our LeNetReg model with elu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MoQkFUlH5OjF"},"outputs":[],"source":["class LeNetReg:\n","    # create the architecture\n","    def build(height, width, depth, classes, lam1 = 0, lam2 = 0, dropout = [0, 0, 0, 0.5]):\n","        # create a feedforward neural net\n","        model = Sequential()\n","        \n","        # add a convolutional layer with 20 5x5 filters and a 2x2 max pooling layer\n","        model.add(Conv2D(32, (5, 5), padding = 'same', input_shape = (height, width, depth),\n","                         kernel_regularizer = l1_l2(l1 = lam1, l2 = lam2)))\n","        model.add(Activation('elu'))\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(dropout[0]))\n","        \n","        # add another convolutional layer with 50 5x5 filters and a 2x2 max pooling layer\n","        model.add(Conv2D(64, (5, 5), padding= 'same', kernel_regularizer = l1_l2(l1 = lam1, l2 = lam2)))\n","        model.add(Activation('elu'))\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(dropout[1]))\n","        \n","        # add another convolutional layer\n","        model.add(Conv2D(128, (5, 5), padding = 'same', kernel_regularizer = l1_l2(l1 = lam1, l2 = lam2)))\n","        model.add(Activation('elu'))\n","        model.add(Dropout(dropout[2]))\n","        \n","        # add a fully-connected layer\n","        model.add(Flatten())\n","        model.add(Dense(500))\n","        model.add(Activation('elu'))\n","        \n","        model.add(Dropout(dropout[3]))\n","        \n","        # add a softmax classifier\n","        model.add(Dense(classes))\n","        model.add(Activation('softmax'))\n","        \n","        # return the constructed model\n","        return model"]},{"cell_type":"markdown","metadata":{"id":"fGnYBS0vmc2h"},"source":["### We decided to try test smaller L1 and L2s with elu becuase we noticed when training the relu model that bigger L1 and L2s dended to lead towards worse accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUregW165k-T","outputId":"ad800baa-efad-4e0f-a0d8-9b5f699dd731"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 1s 11ms/step - loss: 0.0611 - accuracy: 0.9823\n","Dev accuracy for l1 = 0 , l2 = 0 is 0.982326090335846\n","55/55 [==============================] - 1s 12ms/step - loss: 0.2383 - accuracy: 0.9379\n","Dev accuracy for l1 = 0 , l2 = 0.0001 is 0.9378563165664673\n","55/55 [==============================] - 1s 11ms/step - loss: 0.4074 - accuracy: 0.9384\n","Dev accuracy for l1 = 0 , l2 = 0.001 is 0.9384264349937439\n","55/55 [==============================] - 1s 11ms/step - loss: 0.9528 - accuracy: 0.9726\n","Dev accuracy for l1 = 0 , l2 = 0.01 is 0.972633957862854\n","55/55 [==============================] - 1s 11ms/step - loss: 1.8818 - accuracy: 0.8153\n","Dev accuracy for l1 = 0 , l2 = 0.1 is 0.8152793645858765\n","55/55 [==============================] - 1s 11ms/step - loss: 0.7192 - accuracy: 0.9515\n","Dev accuracy for l1 = 0.0001 , l2 = 0 is 0.9515393376350403\n","55/55 [==============================] - 1s 11ms/step - loss: 0.7662 - accuracy: 0.9458\n","Dev accuracy for l1 = 0.0001 , l2 = 0.0001 is 0.9458380937576294\n","55/55 [==============================] - 1s 11ms/step - loss: 1.3311 - accuracy: 0.8187\n","Dev accuracy for l1 = 0.0001 , l2 = 0.001 is 0.8187001347541809\n","55/55 [==============================] - 1s 11ms/step - loss: 0.9417 - accuracy: 0.9783\n","Dev accuracy for l1 = 0.0001 , l2 = 0.01 is 0.9783352613449097\n","55/55 [==============================] - 1s 11ms/step - loss: 1.7227 - accuracy: 0.8233\n","Dev accuracy for l1 = 0.0001 , l2 = 0.1 is 0.8232611417770386\n","55/55 [==============================] - 1s 11ms/step - loss: 1.4306 - accuracy: 0.9715\n","Dev accuracy for l1 = 0.001 , l2 = 0 is 0.9714937210083008\n","55/55 [==============================] - 1s 11ms/step - loss: 1.2772 - accuracy: 0.9778\n","Dev accuracy for l1 = 0.001 , l2 = 0.0001 is 0.9777650833129883\n","55/55 [==============================] - 1s 11ms/step - loss: 1.9653 - accuracy: 0.9151\n","Dev accuracy for l1 = 0.001 , l2 = 0.001 is 0.9150513410568237\n","55/55 [==============================] - 1s 11ms/step - loss: 1.4754 - accuracy: 0.9475\n","Dev accuracy for l1 = 0.001 , l2 = 0.01 is 0.9475484490394592\n","55/55 [==============================] - 1s 11ms/step - loss: 1.5357 - accuracy: 0.8369\n","Dev accuracy for l1 = 0.001 , l2 = 0.1 is 0.8369441032409668\n","55/55 [==============================] - 1s 11ms/step - loss: 2.4860 - accuracy: 0.6038\n","Dev accuracy for l1 = 0.01 , l2 = 0 is 0.6037628054618835\n","55/55 [==============================] - 1s 11ms/step - loss: 2.4190 - accuracy: 0.6499\n","Dev accuracy for l1 = 0.01 , l2 = 0.0001 is 0.6499429941177368\n","55/55 [==============================] - 1s 11ms/step - loss: 2.3828 - accuracy: 0.6517\n","Dev accuracy for l1 = 0.01 , l2 = 0.001 is 0.6516533493995667\n","55/55 [==============================] - 1s 12ms/step - loss: 2.2975 - accuracy: 0.6636\n","Dev accuracy for l1 = 0.01 , l2 = 0.01 is 0.6636260151863098\n","55/55 [==============================] - 1s 12ms/step - loss: 2.8230 - accuracy: 0.5268\n","Dev accuracy for l1 = 0.01 , l2 = 0.1 is 0.5267959237098694\n","55/55 [==============================] - 1s 11ms/step - loss: 7.1246 - accuracy: 0.0211\n","Dev accuracy for l1 = 0.1 , l2 = 0 is 0.021094640716910362\n","55/55 [==============================] - 1s 11ms/step - loss: 7.1441 - accuracy: 0.0194\n","Dev accuracy for l1 = 0.1 , l2 = 0.0001 is 0.019384264945983887\n","55/55 [==============================] - 1s 11ms/step - loss: 7.1246 - accuracy: 0.0200\n","Dev accuracy for l1 = 0.1 , l2 = 0.001 is 0.019954390823841095\n"]}],"source":["best_hyperparameters = [0, 0]\n","best_accuracy = 0\n","\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","maxIt = 20\n","batch_size_total = 20\n","\n","for l1 in [0, 0.0001, 0.001, 0.01, 0.1]:\n","    for l2 in [0, 0.0001, 0.001, 0.01, 0.1]:\n","\n","        model = LeNetReg.build(64, 64, 3, 51, l1, l2)\n","        model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","\n","\n","        H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), \n","                      steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 0)\n","        dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","\n","        print('Dev accuracy for l1 =', l1, ', l2 =', l2, 'is', dev_accuracy['accuracy'])\n","\n","        if dev_accuracy['accuracy'] > best_accuracy: \n","            best_hyperparameters = [l1, l2]\n","            best_accuracy = dev_accuracy['accuracy']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216946,"status":"ok","timestamp":1637018761103,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"siP_Fimz5pxd","outputId":"ad9fb5f6-5a94-404d-af7a-dae75e18fc8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 0s 5ms/step - loss: 0.1868 - accuracy: 0.9436\n","Dev accuracy for dropout percentages [0.1, 0.1, 0.1, 0.5] is 0.9435575604438782\n","55/55 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9647\n","Dev accuracy for dropout percentages [0.2, 0.2, 0.2, 0.5] is 0.9646522402763367\n","55/55 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.8170\n","Dev accuracy for dropout percentages [0.5, 0.5, 0.5, 0.5] is 0.8169897198677063\n","55/55 [==============================] - 0s 5ms/step - loss: 3.2568 - accuracy: 0.3067\n","Dev accuracy for dropout percentages [0.75, 0.75, 0.75, 0.75] is 0.30672746896743774\n"]}],"source":["tf.keras.backend.clear_session()\n","best_dropout = 0\n","best_accuracy = 0\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","for dropout in [[0.1, 0.1, 0.1, 0.5], [0.2, 0.2, 0.2, 0.5], [0.5, 0.5, 0.5, 0.5], [0.75, 0.75, 0.75, 0.75]]:\n","        \n","    model = LeNetReg.build(64, 64, 3, 51, 0, 0, dropout = dropout)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","\n","    maxIt = 20\n","    H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=0)\n","    dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","    print('Dev accuracy for dropout percentages', dropout, 'is', dev_accuracy['accuracy'])\n","    if dev_accuracy['accuracy'] > best_accuracy: \n","        best_dropout = dropout\n","        best_accuracy = dev_accuracy['accuracy']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1637018808372,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"4J5Oaery51UZ","outputId":"732334f4-6545-4853-c0ff-a10a91203aaa"},"outputs":[{"data":{"text/plain":["[0.2, 0.2, 0.2, 0.5]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["best_dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118077,"status":"ok","timestamp":1637018948656,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"U7lrxnj756ke","outputId":"fcdb1b47-e234-4ceb-ccdd-37af69c52ac8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 3s 24ms/step - loss: 3.9590 - accuracy: 0.0248\n","Epoch 2/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.8442 - accuracy: 0.0600\n","Epoch 3/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.7530 - accuracy: 0.0842\n","Epoch 4/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.6658 - accuracy: 0.1171\n","Epoch 5/50\n","87/87 [==============================] - 2s 26ms/step - loss: 3.5553 - accuracy: 0.1338\n","Epoch 6/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.4282 - accuracy: 0.1696\n","Epoch 7/50\n","87/87 [==============================] - 2s 24ms/step - loss: 3.2918 - accuracy: 0.2128\n","Epoch 8/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.1683 - accuracy: 0.2416\n","Epoch 9/50\n","87/87 [==============================] - 2s 23ms/step - loss: 3.0263 - accuracy: 0.2630\n","Epoch 10/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.9163 - accuracy: 0.2832\n","Epoch 11/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.7986 - accuracy: 0.3137\n","Epoch 12/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.6714 - accuracy: 0.3408\n","Epoch 13/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.5386 - accuracy: 0.3685\n","Epoch 14/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.4451 - accuracy: 0.3847\n","Epoch 15/50\n","87/87 [==============================] - 2s 23ms/step - loss: 2.3182 - accuracy: 0.4198\n","Epoch 16/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.2098 - accuracy: 0.4291\n","Epoch 17/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.0990 - accuracy: 0.4569\n","Epoch 18/50\n","87/87 [==============================] - 2s 24ms/step - loss: 2.0263 - accuracy: 0.4787\n","Epoch 19/50\n","87/87 [==============================] - 2s 23ms/step - loss: 1.8983 - accuracy: 0.5012\n","Epoch 20/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.8365 - accuracy: 0.5185\n","Epoch 21/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.7019 - accuracy: 0.5525\n","Epoch 22/50\n","87/87 [==============================] - 2s 23ms/step - loss: 1.6424 - accuracy: 0.5606\n","Epoch 23/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.5491 - accuracy: 0.5859\n","Epoch 24/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.3813 - accuracy: 0.6321\n","Epoch 25/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.3962 - accuracy: 0.6223\n","Epoch 26/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.3289 - accuracy: 0.6407\n","Epoch 27/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.2334 - accuracy: 0.6534\n","Epoch 28/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1335 - accuracy: 0.6845\n","Epoch 29/50\n","87/87 [==============================] - 2s 24ms/step - loss: 1.1225 - accuracy: 0.6794\n","Epoch 30/50\n","87/87 [==============================] - 2s 23ms/step - loss: 1.0659 - accuracy: 0.6967\n","Epoch 31/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.9350 - accuracy: 0.7318\n","Epoch 32/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.9269 - accuracy: 0.7393\n","Epoch 33/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.8328 - accuracy: 0.7624\n","Epoch 34/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.8123 - accuracy: 0.7601\n","Epoch 35/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.7671 - accuracy: 0.7837\n","Epoch 36/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.6751 - accuracy: 0.8039\n","Epoch 37/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.6514 - accuracy: 0.8120\n","Epoch 38/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.6545 - accuracy: 0.8155\n","Epoch 39/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.5688 - accuracy: 0.8253\n","Epoch 40/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.5482 - accuracy: 0.8328\n","Epoch 41/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.5530 - accuracy: 0.8391\n","Epoch 42/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.5187 - accuracy: 0.8478\n","Epoch 43/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.4656 - accuracy: 0.8651\n","Epoch 44/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.4726 - accuracy: 0.8622\n","Epoch 45/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.4328 - accuracy: 0.8645\n","Epoch 46/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.3903 - accuracy: 0.8841\n","Epoch 47/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.4047 - accuracy: 0.8702\n","Epoch 48/50\n","87/87 [==============================] - 2s 23ms/step - loss: 0.4082 - accuracy: 0.8731\n","Epoch 49/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.3235 - accuracy: 0.8962\n","Epoch 50/50\n","87/87 [==============================] - 2s 24ms/step - loss: 0.3753 - accuracy: 0.8829\n"]}],"source":["shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51, 0, 0, dropout=[0.2, 0.2, 0.2, 0.5])\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.01), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 20\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":541,"status":"ok","timestamp":1637018949673,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"Jtde39j-5-F8","outputId":"41aa5197-da28-40bc-9cdd-268c9a30d048"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000\n"]},{"data":{"text/plain":["{'accuracy': 1.0, 'loss': 0.0039517139084637165}"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(x = trainX, y = trainY, return_dict = 1)"]},{"cell_type":"markdown","metadata":{"id":"A67QbicvqbQs"},"source":["### The best L1 and L2 are the same for the Relu model so we decided to use the variables from it to train this model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118075,"status":"ok","timestamp":1637031382808,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"wO8a2jPUqM89","outputId":"da9372b7-0403-46d5-9a50-bbe0cd183d6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 3s 24ms/step - loss: nan - accuracy: 0.0179\n","Epoch 2/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 3/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 4/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 5/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 6/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 7/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 8/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 9/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 10/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 11/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 12/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 13/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 14/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0202\n","Epoch 15/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 16/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 17/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 18/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 19/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 20/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 21/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 22/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 23/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 24/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 25/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0196\n","Epoch 26/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0202\n","Epoch 27/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 28/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 29/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 30/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 31/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 32/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 33/50\n","87/87 [==============================] - 2s 23ms/step - loss: nan - accuracy: 0.0208\n","Epoch 34/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 35/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 36/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 37/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 38/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0196\n","Epoch 39/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0196\n","Epoch 40/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0202\n","Epoch 41/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 42/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 43/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 44/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 45/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0196\n","Epoch 46/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 47/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 48/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 49/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n","Epoch 50/50\n","87/87 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.0208\n"]}],"source":["shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","model = LeNetReg.build(64, 64, 3, 51, 0, 0, dropout=[0.2, 0.2, 0.2, 0.2])\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = SGD(0.05), metrics = ['accuracy'])\n","\n","maxIt = 50\n","batch_size_total = 20\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total),\n","              steps_per_epoch=len(trainX) // batch_size_total, epochs=maxIt, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"A_vRdL2CsCJw"},"source":["### Based on these results with LeNetReg Elu, we have decided to move on to a different model"]},{"cell_type":"markdown","metadata":{"id":"FUwa9ukgnVFB"},"source":["## VGGNet16\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9qZiN_RnTEg"},"outputs":[],"source":["class VGGNet16:\n","    def build(height, width, depth, classes):\n","        model = Sequential(name = 'VGGNet16')\n","        \n","        # conv 1\n","        model.add(Conv2D(64, (3, 3), padding = 'same', input_shape = (height, width, depth)))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 2\n","        model.add(Conv2D(64, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # pool\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(0.25))\n","        \n","        # conv 3\n","        model.add(Conv2D(128, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 4\n","        model.add(Conv2D(128, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # pool\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(0.25))\n","        \n","        # conv 5\n","        model.add(Conv2D(256, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 6\n","        model.add(Conv2D(256, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 7\n","        model.add(Conv2D(256, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # pool\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(0.25))\n","        \n","        # conv 8\n","        model.add(Conv2D(512, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 9\n","        model.add(Conv2D(512, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 10\n","        model.add(Conv2D(512, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # pool\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(0.25))\n","        \n","        # conv 11\n","        model.add(Conv2D(512, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 12\n","        model.add(Conv2D(512, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # conv 13\n","        model.add(Conv2D(512, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        \n","        # pool\n","        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","        model.add(Dropout(0.25))\n","        \n","        model.add(Flatten())\n","        \n","        # fc 14\n","        model.add(Dense(4096))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.5))\n","        \n","        # fc 15\n","        model.add(Dense(4096))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.5))\n","        \n","        # fc 16\n","        model.add(Dense(1000))\n","        model.add(Activation('relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.5))\n","        \n","        # softmax classifier\n","        model.add(Dense(classes))\n","        model.add(Activation('softmax'))\n","        \n","        # return the model\n","        return model"]},{"cell_type":"markdown","metadata":{"id":"ST2oU_BIfEV4"},"source":["### Baseline test for VGGNet16"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163678,"status":"ok","timestamp":1637019195334,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"gfhPCxgjn_du","outputId":"497af229-1e7f-4b47-e8a6-f6218436b507"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","88/88 [==============================] - 6s 38ms/step - loss: 5.4966 - accuracy: 0.0274\n","Epoch 2/50\n","88/88 [==============================] - 3s 34ms/step - loss: 5.3610 - accuracy: 0.0325\n","Epoch 3/50\n","88/88 [==============================] - 3s 34ms/step - loss: 5.0698 - accuracy: 0.0359\n","Epoch 4/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.8562 - accuracy: 0.0353\n","Epoch 5/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.8480 - accuracy: 0.0365\n","Epoch 6/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.7268 - accuracy: 0.0479\n","Epoch 7/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.6480 - accuracy: 0.0439\n","Epoch 8/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.5392 - accuracy: 0.0456\n","Epoch 9/50\n","88/88 [==============================] - 3s 35ms/step - loss: 4.4785 - accuracy: 0.0496\n","Epoch 10/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.4538 - accuracy: 0.0542\n","Epoch 11/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.4923 - accuracy: 0.0507\n","Epoch 12/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.4793 - accuracy: 0.0462\n","Epoch 13/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.3971 - accuracy: 0.0525\n","Epoch 14/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.3423 - accuracy: 0.0536\n","Epoch 15/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.3334 - accuracy: 0.0536\n","Epoch 16/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.2997 - accuracy: 0.0696\n","Epoch 17/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.2288 - accuracy: 0.0696\n","Epoch 18/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.2377 - accuracy: 0.0673\n","Epoch 19/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.1876 - accuracy: 0.0678\n","Epoch 20/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.0917 - accuracy: 0.0821\n","Epoch 21/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.1026 - accuracy: 0.0684\n","Epoch 22/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.1363 - accuracy: 0.0747\n","Epoch 23/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.1067 - accuracy: 0.0821\n","Epoch 24/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.0864 - accuracy: 0.0804\n","Epoch 25/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.0374 - accuracy: 0.0832\n","Epoch 26/50\n","88/88 [==============================] - 3s 35ms/step - loss: 3.9694 - accuracy: 0.0901\n","Epoch 27/50\n","88/88 [==============================] - 3s 34ms/step - loss: 4.0011 - accuracy: 0.0901\n","Epoch 28/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.9435 - accuracy: 0.0924\n","Epoch 29/50\n","88/88 [==============================] - 3s 35ms/step - loss: 3.9431 - accuracy: 0.1043\n","Epoch 30/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.8771 - accuracy: 0.1021\n","Epoch 31/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.9166 - accuracy: 0.1038\n","Epoch 32/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.8991 - accuracy: 0.1106\n","Epoch 33/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.8625 - accuracy: 0.1026\n","Epoch 34/50\n","88/88 [==============================] - 3s 35ms/step - loss: 3.8920 - accuracy: 0.0935\n","Epoch 35/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.8418 - accuracy: 0.1055\n","Epoch 36/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.8351 - accuracy: 0.1055\n","Epoch 37/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.8297 - accuracy: 0.1089\n","Epoch 38/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.7282 - accuracy: 0.1129\n","Epoch 39/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.7019 - accuracy: 0.1237\n","Epoch 40/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.7626 - accuracy: 0.1146\n","Epoch 41/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.6701 - accuracy: 0.1328\n","Epoch 42/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.6528 - accuracy: 0.1403\n","Epoch 43/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.6425 - accuracy: 0.1437\n","Epoch 44/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.6325 - accuracy: 0.1311\n","Epoch 45/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.6060 - accuracy: 0.1266\n","Epoch 46/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.6140 - accuracy: 0.1385\n","Epoch 47/50\n","88/88 [==============================] - 3s 35ms/step - loss: 3.5234 - accuracy: 0.1414\n","Epoch 48/50\n","88/88 [==============================] - 3s 34ms/step - loss: 3.5123 - accuracy: 0.1403\n","Epoch 49/50\n","88/88 [==============================] - 3s 35ms/step - loss: 3.5347 - accuracy: 0.1374\n","Epoch 50/50\n","88/88 [==============================] - 3s 35ms/step - loss: 3.4457 - accuracy: 0.1556\n"]}],"source":["model = VGGNet16.build(64, 64, 3, 51)\n","opt = SGD(.01)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","batch_size_total = 20\n","maxIt = 50\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), batch_size = batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"MLIYkSNBfJ-m"},"source":["### Finding the best learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294683,"status":"ok","timestamp":1637019840956,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"wcTdPzNwoTFX","outputId":"99a1bc7c-2874-4387-b1c7-c1cd864b52a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 2s 17ms/step - loss: 3.4336 - accuracy: 0.1380\n","Dev accuracy for learning rate  0.01 is 0.13797035813331604\n","55/55 [==============================] - 1s 13ms/step - loss: 3.4166 - accuracy: 0.1442\n","Dev accuracy for learning rate  0.02 is 0.14424173533916473\n","55/55 [==============================] - 1s 12ms/step - loss: 3.6357 - accuracy: 0.1129\n","Dev accuracy for learning rate  0.05 is 0.11288483440876007\n","55/55 [==============================] - 1s 12ms/step - loss: 3.7885 - accuracy: 0.1129\n","Dev accuracy for learning rate  0.1 is 0.11288483440876007\n"]}],"source":["tf.keras.backend.clear_session()\n","best_learning_rate = 0\n","best_accuracy = 0\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","\n","\n","for i in [.01, .02, .05, .1]:\n","    model = VGGNet16.build(64, 64, 3, 51)\n","    opt = SGD(learning_rate = i, decay = 0.3 / 100, nesterov = True)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","    \n","    maxIt = 20\n","    H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), \n","                  batch_size = batch_size_total, epochs = maxIt, verbose = 0)\n","    dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","    print('Dev accuracy for learning rate ', i, 'is', dev_accuracy['accuracy'])\n","    if dev_accuracy['accuracy'] > best_accuracy: \n","        best_learning_rate = i\n","        best_accuracy = dev_accuracy['accuracy']\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1637019848355,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"vJI0OKhL83Ar","outputId":"17937cbc-3bad-42ea-831b-30bcafdfb27f"},"outputs":[{"data":{"text/plain":["0.02"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["best_learning_rate"]},{"cell_type":"markdown","metadata":{"id":"eEp7-19nfWKw"},"source":["### Finding the best momentum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6h2Xx2Ib_NGM"},"outputs":[],"source":["tf.keras.backend.clear_session()\n","best_momentum = 0\n","best_accuracy = 0\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","\n","\n","for i in [.1, .2, .5, .9]:\n","    model = VGGNet16.build(64, 64, 3, 51)\n","    opt = SGD(learning_rate = best_learning_rate, decay = 0.3 / 100, momentum = i, nesterov = True)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","    \n","    maxIt = 20\n","    H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), \n","                  batch_size = batch_size_total, epochs = maxIt, verbose = 0)\n","    dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","    print('Dev accuracy for a momentum of ', i, 'is', dev_accuracy['accuracy'])\n","    if dev_accuracy['accuracy'] > best_accuracy: \n","        best_momentum = i\n","        best_accuracy = dev_accuracy['accuracy']"]},{"cell_type":"markdown","metadata":{"id":"WagtIkzifZtl"},"source":["### model with the best hyperparameters all in it"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201877,"status":"ok","timestamp":1637020602365,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"P7QsLLbsA7m8","outputId":"5986df10-9fe1-48bc-f76f-b847a8c2e2a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 5s 35ms/step - loss: 5.4478 - accuracy: 0.0208\n","Epoch 2/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.1228 - accuracy: 0.0283\n","Epoch 3/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.9359 - accuracy: 0.0294\n","Epoch 4/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.8480 - accuracy: 0.0283\n","Epoch 5/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.7018 - accuracy: 0.0473\n","Epoch 6/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.6486 - accuracy: 0.0283\n","Epoch 7/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.5806 - accuracy: 0.0421\n","Epoch 8/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.5300 - accuracy: 0.0490\n","Epoch 9/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.4686 - accuracy: 0.0421\n","Epoch 10/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.5472 - accuracy: 0.0381\n","Epoch 11/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.4259 - accuracy: 0.0415\n","Epoch 12/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.4533 - accuracy: 0.0496\n","Epoch 13/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3190 - accuracy: 0.0490\n","Epoch 14/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3538 - accuracy: 0.0548\n","Epoch 15/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3374 - accuracy: 0.0565\n","Epoch 16/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2961 - accuracy: 0.0513\n","Epoch 17/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2823 - accuracy: 0.0531\n","Epoch 18/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2986 - accuracy: 0.0467\n","Epoch 19/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2966 - accuracy: 0.0484\n","Epoch 20/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2234 - accuracy: 0.0577\n","Epoch 21/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2597 - accuracy: 0.0559\n","Epoch 22/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2318 - accuracy: 0.0554\n","Epoch 23/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2222 - accuracy: 0.0692\n","Epoch 24/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1799 - accuracy: 0.0582\n","Epoch 25/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1384 - accuracy: 0.0704\n","Epoch 26/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1501 - accuracy: 0.0606\n","Epoch 27/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0732 - accuracy: 0.0669\n","Epoch 28/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1439 - accuracy: 0.0571\n","Epoch 29/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1042 - accuracy: 0.0652\n","Epoch 30/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0999 - accuracy: 0.0652\n","Epoch 31/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0910 - accuracy: 0.0669\n","Epoch 32/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0750 - accuracy: 0.0657\n","Epoch 33/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1068 - accuracy: 0.0738\n","Epoch 34/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0433 - accuracy: 0.0704\n","Epoch 35/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0885 - accuracy: 0.0617\n","Epoch 36/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0377 - accuracy: 0.0663\n","Epoch 37/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9809 - accuracy: 0.0709\n","Epoch 38/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0376 - accuracy: 0.0813\n","Epoch 39/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0197 - accuracy: 0.0732\n","Epoch 40/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0201 - accuracy: 0.0709\n","Epoch 41/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9697 - accuracy: 0.0640\n","Epoch 42/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0360 - accuracy: 0.0738\n","Epoch 43/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0208 - accuracy: 0.0830\n","Epoch 44/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9604 - accuracy: 0.0813\n","Epoch 45/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9551 - accuracy: 0.0859\n","Epoch 46/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9778 - accuracy: 0.0773\n","Epoch 47/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9671 - accuracy: 0.0854\n","Epoch 48/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9513 - accuracy: 0.0796\n","Epoch 49/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9676 - accuracy: 0.0819\n","Epoch 50/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9245 - accuracy: 0.0836\n"]}],"source":["model = VGGNet16.build(64, 64, 3, 51)\n","opt = opt = SGD(learning_rate = best_learning_rate, decay = 0.3 / 100, momentum = best_momentum, nesterov = True)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","batch_size_total = 20\n","maxIt = 50\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"Rag8emqosiOS"},"source":["### Here we took the best model and brough the decay down to 0.1/100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219210,"status":"ok","timestamp":1637031959809,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"n8tTIfIesWLO","outputId":"cbf9fe6f-4278-4592-ce4e-67ac2e2eb3f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 6s 39ms/step - loss: 7.0403 - accuracy: 0.0190\n","Epoch 2/50\n","87/87 [==============================] - 3s 36ms/step - loss: 6.7606 - accuracy: 0.0242\n","Epoch 3/50\n","87/87 [==============================] - 3s 35ms/step - loss: 6.2575 - accuracy: 0.0283\n","Epoch 4/50\n","87/87 [==============================] - 3s 35ms/step - loss: 6.1700 - accuracy: 0.0288\n","Epoch 5/50\n","87/87 [==============================] - 3s 36ms/step - loss: 5.7848 - accuracy: 0.0329\n","Epoch 6/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.6603 - accuracy: 0.0311\n","Epoch 7/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.5354 - accuracy: 0.0381\n","Epoch 8/50\n","87/87 [==============================] - 3s 36ms/step - loss: 5.3701 - accuracy: 0.0334\n","Epoch 9/50\n","87/87 [==============================] - 3s 36ms/step - loss: 5.2381 - accuracy: 0.0323\n","Epoch 10/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.0776 - accuracy: 0.0340\n","Epoch 11/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.0380 - accuracy: 0.0363\n","Epoch 12/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.9387 - accuracy: 0.0358\n","Epoch 13/50\n","87/87 [==============================] - 3s 36ms/step - loss: 5.0006 - accuracy: 0.0345\n","Epoch 14/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.7782 - accuracy: 0.0415\n","Epoch 15/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.8321 - accuracy: 0.0386\n","Epoch 16/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.6934 - accuracy: 0.0450\n","Epoch 17/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.6858 - accuracy: 0.0427\n","Epoch 18/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.7499 - accuracy: 0.0352\n","Epoch 19/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.5945 - accuracy: 0.0548\n","Epoch 20/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.5825 - accuracy: 0.0542\n","Epoch 21/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.5810 - accuracy: 0.0577\n","Epoch 22/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.5053 - accuracy: 0.0634\n","Epoch 23/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.4620 - accuracy: 0.0600\n","Epoch 24/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.4655 - accuracy: 0.0525\n","Epoch 25/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3918 - accuracy: 0.0652\n","Epoch 26/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2800 - accuracy: 0.0565\n","Epoch 27/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3256 - accuracy: 0.0548\n","Epoch 28/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.3316 - accuracy: 0.0698\n","Epoch 29/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2952 - accuracy: 0.0692\n","Epoch 30/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2068 - accuracy: 0.0623\n","Epoch 31/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2260 - accuracy: 0.0634\n","Epoch 32/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1894 - accuracy: 0.0617\n","Epoch 33/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1843 - accuracy: 0.0732\n","Epoch 34/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1297 - accuracy: 0.0744\n","Epoch 35/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1249 - accuracy: 0.0681\n","Epoch 36/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1537 - accuracy: 0.0623\n","Epoch 37/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1199 - accuracy: 0.0657\n","Epoch 38/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0975 - accuracy: 0.0732\n","Epoch 39/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0955 - accuracy: 0.0825\n","Epoch 40/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0836 - accuracy: 0.0761\n","Epoch 41/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0729 - accuracy: 0.0779\n","Epoch 42/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0833 - accuracy: 0.0761\n","Epoch 43/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9827 - accuracy: 0.0905\n","Epoch 44/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0162 - accuracy: 0.0819\n","Epoch 45/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9653 - accuracy: 0.0767\n","Epoch 46/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0087 - accuracy: 0.0761\n","Epoch 47/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9058 - accuracy: 0.0923\n","Epoch 48/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9527 - accuracy: 0.0836\n","Epoch 49/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9384 - accuracy: 0.0802\n","Epoch 50/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9219 - accuracy: 0.0871\n"]}],"source":["model = VGGNet16.build(64, 64, 3, 51)\n","opt = opt = SGD(learning_rate = best_learning_rate, decay = 0.1 / 100, momentum = best_momentum, nesterov = True)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","batch_size_total = 20\n","maxIt = 50\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"Xr16syHfu01B"},"source":["### We saw roughly the same accuracy with the decay lowered to 0.1/100 so we decided to go the other way and raise it to 0.5/100"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218453,"status":"ok","timestamp":1637032564941,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"aVU5ye4vuzOI","outputId":"ad0c5ab5-085e-4ca8-eac3-9854fb62d7cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 5s 36ms/step - loss: 6.5450 - accuracy: 0.0196\n","Epoch 2/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.9360 - accuracy: 0.0213\n","Epoch 3/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.5910 - accuracy: 0.0254\n","Epoch 4/50\n","87/87 [==============================] - 3s 36ms/step - loss: 5.4118 - accuracy: 0.0208\n","Epoch 5/50\n","87/87 [==============================] - 3s 36ms/step - loss: 5.2099 - accuracy: 0.0271\n","Epoch 6/50\n","87/87 [==============================] - 3s 35ms/step - loss: 5.0568 - accuracy: 0.0346\n","Epoch 7/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.9875 - accuracy: 0.0300\n","Epoch 8/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.8886 - accuracy: 0.0438\n","Epoch 9/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.7884 - accuracy: 0.0352\n","Epoch 10/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.6562 - accuracy: 0.0363\n","Epoch 11/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.7252 - accuracy: 0.0409\n","Epoch 12/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.6892 - accuracy: 0.0438\n","Epoch 13/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.5352 - accuracy: 0.0421\n","Epoch 14/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.5634 - accuracy: 0.0450\n","Epoch 15/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.4990 - accuracy: 0.0554\n","Epoch 16/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.4981 - accuracy: 0.0513\n","Epoch 17/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.5173 - accuracy: 0.0456\n","Epoch 18/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3524 - accuracy: 0.0600\n","Epoch 19/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.4076 - accuracy: 0.0467\n","Epoch 20/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.4158 - accuracy: 0.0450\n","Epoch 21/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3254 - accuracy: 0.0536\n","Epoch 22/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3474 - accuracy: 0.0548\n","Epoch 23/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.3067 - accuracy: 0.0559\n","Epoch 24/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.3693 - accuracy: 0.0456\n","Epoch 25/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.3238 - accuracy: 0.0507\n","Epoch 26/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2743 - accuracy: 0.0513\n","Epoch 27/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2407 - accuracy: 0.0606\n","Epoch 28/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2764 - accuracy: 0.0588\n","Epoch 29/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2867 - accuracy: 0.0588\n","Epoch 30/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2648 - accuracy: 0.0588\n","Epoch 31/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2368 - accuracy: 0.0606\n","Epoch 32/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2025 - accuracy: 0.0681\n","Epoch 33/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2187 - accuracy: 0.0623\n","Epoch 34/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.2221 - accuracy: 0.0617\n","Epoch 35/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1947 - accuracy: 0.0629\n","Epoch 36/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.2324 - accuracy: 0.0646\n","Epoch 37/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.1229 - accuracy: 0.0773\n","Epoch 38/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1554 - accuracy: 0.0657\n","Epoch 39/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1659 - accuracy: 0.0669\n","Epoch 40/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1100 - accuracy: 0.0617\n","Epoch 41/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1152 - accuracy: 0.0692\n","Epoch 42/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0534 - accuracy: 0.0692\n","Epoch 43/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.1207 - accuracy: 0.0732\n","Epoch 44/50\n","87/87 [==============================] - 3s 35ms/step - loss: 4.0947 - accuracy: 0.0669\n","Epoch 45/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0933 - accuracy: 0.0819\n","Epoch 46/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0999 - accuracy: 0.0721\n","Epoch 47/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0895 - accuracy: 0.0773\n","Epoch 48/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0771 - accuracy: 0.0646\n","Epoch 49/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0824 - accuracy: 0.0784\n","Epoch 50/50\n","87/87 [==============================] - 3s 36ms/step - loss: 4.0408 - accuracy: 0.0721\n"]}],"source":["model = VGGNet16.build(64, 64, 3, 51)\n","opt = opt = SGD(learning_rate = best_learning_rate, decay = 0.5 / 100, momentum = best_momentum, nesterov = True)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","batch_size_total = 20\n","maxIt = 50\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"3qXlsPyYxqj6"},"source":["### This model ended up not doing as well as we would have hoped with the decay change so we decided to move on to a different model"]},{"cell_type":"markdown","metadata":{"id":"1xsnqwHgQc-3"},"source":["## MiniGoogLeNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MvqKd9eE9Jb"},"outputs":[],"source":["class MiniGoogLeNet:\n","    def convolution_module(x, K, kX, kY, stride, channelsDim, padding=\"same\"):\n","        # create a CONV -> BN -> RELU sequence\n","        x = Conv2D(K, (kX, kY), strides = stride, padding = padding)(x)\n","        x = BatchNormalization(axis = channelsDim)(x)\n","        x = Activation('relu')(x)\n","        \n","        # return the output\n","        return x\n","    \n","    def inception_module(x, numberOf1x1Kernels, numberOf3x3Kernels, channelsDim):\n","        # define two \"parallel\" convolutions of size 1x1 and 3x3 concatenated across the channels dimension\n","        convolution_1x1 = MiniGoogLeNet.convolution_module(x, numberOf1x1Kernels, 1, 1, (1, 1), channelsDim)\n","        convolution_3x3 = MiniGoogLeNet.convolution_module(x, numberOf3x3Kernels, 3, 3, (1, 1), channelsDim)\n","        x = concatenate([convolution_1x1, convolution_3x3], axis = channelsDim)\n","        \n","        return x\n","        \n","    def downsample_module(x, K, channelsDim):\n","        # define a CONV and POOL and then concatenate across the channels dimension\n","        convolution_3x3 = MiniGoogLeNet.convolution_module(x, K, 3, 3, (2, 2), channelsDim, padding = 'valid')\n","        pool = MaxPooling2D((3, 3), strides = (2, 2))(x)\n","        x = concatenate([convolution_3x3, pool], axis = channelsDim)\n","        \n","        return x\n","    \n","    def build(width, height, depth, classes):\n","        inputShape = (height, width, depth)\n","        channelsDim = -1\n","        \n","        \n","        # define the model input and first CONV module\n","        inputs = Input(shape = inputShape)\n","        x = MiniGoogLeNet.convolution_module(inputs, 96, 3, 3, (1, 1), channelsDim)\n","        \n","        # two inception modules followed by a downsample module\n","        x = MiniGoogLeNet.inception_module(x, 32, 32, channelsDim)\n","        x = MiniGoogLeNet.inception_module(x, 32, 48, channelsDim)\n","        x = MiniGoogLeNet.downsample_module(x, 80, channelsDim)\n","        \n","        # four inception modules followed by a downsample module\n","        x = MiniGoogLeNet.inception_module(x, 112, 48, channelsDim)\n","        x = MiniGoogLeNet.inception_module(x, 96, 64, channelsDim)\n","        x = MiniGoogLeNet.inception_module(x, 80, 80, channelsDim)\n","        x = MiniGoogLeNet.inception_module(x, 48, 96, channelsDim)\n","        x = MiniGoogLeNet.downsample_module(x, 96, channelsDim)\n","        \n","        # two inception modules followed by global POOL and dropout\n","        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n","        x = MiniGoogLeNet.inception_module(x, 176, 160, channelsDim)\n","        x = AveragePooling2D((7, 7))(x)\n","        x = Dropout(0.5)(x)\n","        \n","        # softmax classifier\n","        x = Flatten()(x)\n","        x = Dense(classes)(x)\n","        x = Activation('softmax')(x)\n","        \n","        # create a model\n","        model = Model(inputs, x, name='MiniGoogLeNet')\n","        \n","        # return the model\n","        return model"]},{"cell_type":"markdown","metadata":{"id":"VahLsscRdzWI"},"source":["### Baseline model for MiniGoogLeNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213366,"status":"ok","timestamp":1637022701410,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"2nkd4KkwFLu5","outputId":"3db614c4-81e3-497d-df87-26c691b34632"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","87/87 [==============================] - 5s 36ms/step - loss: 4.3499 - accuracy: 0.0467\n","Epoch 2/50\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9293 - accuracy: 0.0721\n","Epoch 3/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.6703 - accuracy: 0.1165\n","Epoch 4/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.5693 - accuracy: 0.1194\n","Epoch 5/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.4293 - accuracy: 0.1522\n","Epoch 6/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.3397 - accuracy: 0.1724\n","Epoch 7/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.2212 - accuracy: 0.1909\n","Epoch 8/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.1377 - accuracy: 0.2145\n","Epoch 9/50\n","87/87 [==============================] - 3s 36ms/step - loss: 3.0423 - accuracy: 0.2388\n","Epoch 10/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.9704 - accuracy: 0.2486\n","Epoch 11/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.8665 - accuracy: 0.2641\n","Epoch 12/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.8332 - accuracy: 0.2699\n","Epoch 13/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.6803 - accuracy: 0.3028\n","Epoch 14/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.6445 - accuracy: 0.3068\n","Epoch 15/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.4565 - accuracy: 0.3604\n","Epoch 16/50\n","87/87 [==============================] - 3s 37ms/step - loss: 2.4048 - accuracy: 0.3610\n","Epoch 17/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.3147 - accuracy: 0.3881\n","Epoch 18/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.2220 - accuracy: 0.4135\n","Epoch 19/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.1188 - accuracy: 0.4366\n","Epoch 20/50\n","87/87 [==============================] - 3s 36ms/step - loss: 2.0386 - accuracy: 0.4498\n","Epoch 21/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.9650 - accuracy: 0.4614\n","Epoch 22/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.8574 - accuracy: 0.4902\n","Epoch 23/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7920 - accuracy: 0.5046\n","Epoch 24/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7372 - accuracy: 0.5196\n","Epoch 25/50\n","87/87 [==============================] - 3s 37ms/step - loss: 1.5991 - accuracy: 0.5473\n","Epoch 26/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.5525 - accuracy: 0.5634\n","Epoch 27/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.5273 - accuracy: 0.5686\n","Epoch 28/50\n","87/87 [==============================] - 3s 37ms/step - loss: 1.4038 - accuracy: 0.6055\n","Epoch 29/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.2676 - accuracy: 0.6471\n","Epoch 30/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.2870 - accuracy: 0.6286\n","Epoch 31/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.2109 - accuracy: 0.6551\n","Epoch 32/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.1366 - accuracy: 0.6724\n","Epoch 33/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.0482 - accuracy: 0.7076\n","Epoch 34/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.0828 - accuracy: 0.6805\n","Epoch 35/50\n","87/87 [==============================] - 3s 36ms/step - loss: 1.0133 - accuracy: 0.7203\n","Epoch 36/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.9130 - accuracy: 0.7364\n","Epoch 37/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.8615 - accuracy: 0.7497\n","Epoch 38/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.8545 - accuracy: 0.7463\n","Epoch 39/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.7772 - accuracy: 0.7757\n","Epoch 40/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6613 - accuracy: 0.8051\n","Epoch 41/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6937 - accuracy: 0.7878\n","Epoch 42/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6322 - accuracy: 0.8166\n","Epoch 43/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5664 - accuracy: 0.8328\n","Epoch 44/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5537 - accuracy: 0.8356\n","Epoch 45/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5339 - accuracy: 0.8431\n","Epoch 46/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5283 - accuracy: 0.8506\n","Epoch 47/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4765 - accuracy: 0.8581\n","Epoch 48/50\n","87/87 [==============================] - 3s 37ms/step - loss: 0.3941 - accuracy: 0.8875\n","Epoch 49/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3677 - accuracy: 0.8899\n","Epoch 50/50\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4331 - accuracy: 0.8691\n"]}],"source":["maxIt = 50\n","initialLearningRate = 0.01\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","def polynomial_decay(epoch):\n","    maxEpochs = numberOfEpochs\n","    baseLearningRate = initialLearningRate\n","    power = 1.0\n","    \n","    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n","    \n","    # return the learning rate\n","    return alpha\n","\n","\n","callbacks = [LearningRateScheduler(polynomial_decay)]\n","\n","opt = SGD(learning_rate = initialLearningRate, momentum=0.9)\n","model = MiniGoogLeNet.build(width = 64, height = 64, depth = 3, classes = 51)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n","\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"R9HYcg5WeHFA"},"source":["### This is where we tried to get a good learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1683256,"status":"ok","timestamp":1637025989721,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"cVKANWp3FLsS","outputId":"e8f65aff-0730-484b-96aa-902d570e0e0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 1s 16ms/step - loss: 0.0081 - accuracy: 0.9983\n","Dev accuracy for learning rate  0.01 is 0.9982896447181702\n","55/55 [==============================] - 1s 16ms/step - loss: 0.0241 - accuracy: 0.9937\n","Dev accuracy for learning rate  0.02 is 0.9937286376953125\n","55/55 [==============================] - 1s 16ms/step - loss: 0.0163 - accuracy: 1.0000\n","Dev accuracy for learning rate  0.05 is 1.0\n","55/55 [==============================] - 1s 16ms/step - loss: 0.0986 - accuracy: 0.9738\n","Dev accuracy for learning rate  0.1 is 0.973774254322052\n"]}],"source":["maxIt = 100\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","\n","best_accuracy = 0\n","best_learning_rate = 0\n","\n","def polynomial_decay(epoch):\n","    maxEpochs = numberOfEpochs\n","    baseLearningRate = initialLearningRate\n","    power = 1.0\n","    \n","    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n","    \n","    return alpha\n","\n","\n","callbacks = [LearningRateScheduler(polynomial_decay)]\n","\n","\n","for rate in [.01, .02, .05, .1]:\n","\n","    opt = SGD(learning_rate = rate, momentum=0.9)\n","    model = MiniGoogLeNet.build(width = 64, height = 64, depth = 3, classes = 51)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n","\n","    H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), \n","                  steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 0)\n","    dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","    print('Dev accuracy for learning rate ', rate, 'is', dev_accuracy['accuracy'])\n","    if dev_accuracy['accuracy'] > best_accuracy: \n","        best_learning_rate = rate\n","        best_accuracy = dev_accuracy['accuracy']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1637023164816,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"Sxsu5-LRFLpg","outputId":"83b841c9-c341-44be-e539-364fba2f38d0"},"outputs":[{"data":{"text/plain":["0.01"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["best_learning_rate"]},{"cell_type":"markdown","metadata":{"id":"WIAKNOJxeOOw"},"source":["### This is where we tried to get a good momentum"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1715650,"status":"ok","timestamp":1637034987073,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"LxQJRE90FLlr","outputId":"65b4f9c1-e3b9-410d-c8a1-fea5588aadd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["55/55 [==============================] - 1s 16ms/step - loss: 0.0108 - accuracy: 0.9994\n","Dev accuracy for momentum  0.1 is 0.9994298815727234\n","55/55 [==============================] - 1s 16ms/step - loss: 0.0052 - accuracy: 0.9994\n","Dev accuracy for momentum  0.2 is 0.9994298815727234\n","55/55 [==============================] - 1s 16ms/step - loss: 0.0120 - accuracy: 0.9994\n","Dev accuracy for momentum  0.5 is 0.9994298815727234\n","55/55 [==============================] - 1s 16ms/step - loss: 0.0257 - accuracy: 0.9960\n","Dev accuracy for momentum  0.9 is 0.996009111404419\n"]}],"source":["maxIt = 100\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","\n","best_accuracy = 0\n","best_momentum = 0\n","\n","def polynomial_decay(epoch):\n","    maxEpochs = numberOfEpochs\n","    baseLearningRate = best_learning_rate\n","    power = 1.0\n","    \n","    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n","    \n","    return alpha\n","\n","\n","callbacks = [LearningRateScheduler(polynomial_decay)]\n","\n","\n","for rate in [.1, .2, .5, .9]:\n","\n","    opt = SGD(learning_rate = best_learning_rate, momentum = rate)\n","    model = MiniGoogLeNet.build(width = 64, height = 64, depth = 3, classes = 51)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n","\n","    H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), \n","                  steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 0)\n","    dev_accuracy = model.evaluate(x = trainX, y = trainY, return_dict=True)\n","    print('Dev accuracy for momentum ', rate, 'is', dev_accuracy['accuracy'])\n","    if dev_accuracy['accuracy'] > best_accuracy: \n","        best_momentum = rate\n","        best_accuracy = dev_accuracy['accuracy']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1637034987073,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"eOW8dqRmNjs-","outputId":"0d47defc-3cd8-4541-dbf3-1bb93289243e"},"outputs":[{"data":{"text/plain":["0.1"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["best_momentum"]},{"cell_type":"markdown","metadata":{"id":"JFgdF2ZHeVFF"},"source":["### Model with the best learning rate and best momentum"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409154,"status":"ok","timestamp":1637035396224,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"bSIGwjT7NzL2","outputId":"80ede1ee-59c1-46e2-ff9d-a6c167dfcd3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","87/87 [==============================] - 5s 36ms/step - loss: 4.3385 - accuracy: 0.0402\n","Epoch 2/100\n","87/87 [==============================] - 3s 35ms/step - loss: 3.9219 - accuracy: 0.0738\n","Epoch 3/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.7405 - accuracy: 0.1044\n","Epoch 4/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.5301 - accuracy: 0.1373\n","Epoch 5/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.4049 - accuracy: 0.1603\n","Epoch 6/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.2871 - accuracy: 0.1880\n","Epoch 7/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.2051 - accuracy: 0.1972\n","Epoch 8/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.0693 - accuracy: 0.2330\n","Epoch 9/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.9701 - accuracy: 0.2411\n","Epoch 10/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.8606 - accuracy: 0.2803\n","Epoch 11/100\n","87/87 [==============================] - 3s 37ms/step - loss: 2.7312 - accuracy: 0.3057\n","Epoch 12/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.6093 - accuracy: 0.3189\n","Epoch 13/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.5457 - accuracy: 0.3512\n","Epoch 14/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.4311 - accuracy: 0.3627\n","Epoch 15/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.3812 - accuracy: 0.3777\n","Epoch 16/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.2692 - accuracy: 0.3956\n","Epoch 17/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.1351 - accuracy: 0.4262\n","Epoch 18/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.0808 - accuracy: 0.4435\n","Epoch 19/100\n","87/87 [==============================] - 3s 37ms/step - loss: 2.0088 - accuracy: 0.4625\n","Epoch 20/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.8887 - accuracy: 0.4735\n","Epoch 21/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.8029 - accuracy: 0.4988\n","Epoch 22/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7732 - accuracy: 0.5213\n","Epoch 23/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.6916 - accuracy: 0.5398\n","Epoch 24/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.6149 - accuracy: 0.5507\n","Epoch 25/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.5022 - accuracy: 0.5871\n","Epoch 26/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.4454 - accuracy: 0.6067\n","Epoch 27/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.3840 - accuracy: 0.6067\n","Epoch 28/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.3389 - accuracy: 0.6269\n","Epoch 29/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.2419 - accuracy: 0.6453\n","Epoch 30/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.1720 - accuracy: 0.6696\n","Epoch 31/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.0482 - accuracy: 0.6909\n","Epoch 32/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.0462 - accuracy: 0.7076\n","Epoch 33/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.9769 - accuracy: 0.7336\n","Epoch 34/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.9604 - accuracy: 0.7353\n","Epoch 35/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.8962 - accuracy: 0.7301\n","Epoch 36/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.8823 - accuracy: 0.7393\n","Epoch 37/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.8493 - accuracy: 0.7509\n","Epoch 38/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.7831 - accuracy: 0.7832\n","Epoch 39/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.7338 - accuracy: 0.7855\n","Epoch 40/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.7196 - accuracy: 0.7924\n","Epoch 41/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6816 - accuracy: 0.7999\n","Epoch 42/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6493 - accuracy: 0.8103\n","Epoch 43/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5323 - accuracy: 0.8495\n","Epoch 44/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4773 - accuracy: 0.8702\n","Epoch 45/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4976 - accuracy: 0.8604\n","Epoch 46/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4545 - accuracy: 0.8754\n","Epoch 47/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.4463 - accuracy: 0.8754\n","Epoch 48/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4128 - accuracy: 0.8806\n","Epoch 49/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.3274 - accuracy: 0.9170\n","Epoch 50/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3717 - accuracy: 0.9002\n","Epoch 51/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3380 - accuracy: 0.9072\n","Epoch 52/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3085 - accuracy: 0.9146\n","Epoch 53/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3157 - accuracy: 0.9083\n","Epoch 54/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3109 - accuracy: 0.9146\n","Epoch 55/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2833 - accuracy: 0.9239\n","Epoch 56/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.2184 - accuracy: 0.9435\n","Epoch 57/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.2586 - accuracy: 0.9285\n","Epoch 58/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.2344 - accuracy: 0.9394\n","Epoch 59/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2203 - accuracy: 0.9377\n","Epoch 60/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2048 - accuracy: 0.9446\n","Epoch 61/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2473 - accuracy: 0.9331\n","Epoch 62/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1815 - accuracy: 0.9539\n","Epoch 63/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1817 - accuracy: 0.9498\n","Epoch 64/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1666 - accuracy: 0.9533\n","Epoch 65/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.1470 - accuracy: 0.9573\n","Epoch 66/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1540 - accuracy: 0.9608\n","Epoch 67/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1805 - accuracy: 0.9516\n","Epoch 68/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.1500 - accuracy: 0.9614\n","Epoch 69/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1208 - accuracy: 0.9700\n","Epoch 70/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.1340 - accuracy: 0.9671\n","Epoch 71/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1128 - accuracy: 0.9729\n","Epoch 72/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.1221 - accuracy: 0.9644\n","Epoch 73/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1246 - accuracy: 0.9683\n","Epoch 74/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.1234 - accuracy: 0.9706\n","Epoch 75/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.1450 - accuracy: 0.9556\n","Epoch 76/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0957 - accuracy: 0.9775\n","Epoch 77/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0799 - accuracy: 0.9833\n","Epoch 78/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1040 - accuracy: 0.9723\n","Epoch 79/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0886 - accuracy: 0.9804\n","Epoch 80/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1039 - accuracy: 0.9723\n","Epoch 81/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0748 - accuracy: 0.9862\n","Epoch 82/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0844 - accuracy: 0.9815\n","Epoch 83/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1095 - accuracy: 0.9712\n","Epoch 84/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0956 - accuracy: 0.9752\n","Epoch 85/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0797 - accuracy: 0.9821\n","Epoch 86/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0621 - accuracy: 0.9856\n","Epoch 87/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0793 - accuracy: 0.9792\n","Epoch 88/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0833 - accuracy: 0.9781\n","Epoch 89/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0748 - accuracy: 0.9833\n","Epoch 90/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0578 - accuracy: 0.9890\n","Epoch 91/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0562 - accuracy: 0.9867\n","Epoch 92/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0805 - accuracy: 0.9758\n","Epoch 93/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0486 - accuracy: 0.9919\n","Epoch 94/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0637 - accuracy: 0.9839\n","Epoch 95/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0565 - accuracy: 0.9815\n","Epoch 96/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0584 - accuracy: 0.9844\n","Epoch 97/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0973 - accuracy: 0.9729\n","Epoch 98/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0922 - accuracy: 0.9723\n","Epoch 99/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0452 - accuracy: 0.9937\n","Epoch 100/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0444 - accuracy: 0.9890\n"]}],"source":["maxIt = 100\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","def polynomial_decay(epoch):\n","    maxEpochs = numberOfEpochs\n","    baseLearningRate = best_learning_rate\n","    power = 1.0\n","    \n","    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n","    \n","    # return the learning rate\n","    return alpha\n","\n","\n","callbacks = [LearningRateScheduler(polynomial_decay)]\n","\n","opt = SGD(learning_rate = best_learning_rate, momentum=best_momentum)\n","model = MiniGoogLeNet.build(width = 64, height = 64, depth = 3, classes = 51)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n","\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"a7tsjLHk9KB9"},"source":["### Here we made the base learning rate .01"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413743,"status":"ok","timestamp":1637036043046,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"5X3_ilNVx-lX","outputId":"4df6e570-b6de-42b4-b3a5-08c02b03d253"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","87/87 [==============================] - 5s 36ms/step - loss: 4.2814 - accuracy: 0.0473\n","Epoch 2/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.9122 - accuracy: 0.0773\n","Epoch 3/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.6933 - accuracy: 0.1194\n","Epoch 4/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.5327 - accuracy: 0.1401\n","Epoch 5/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.3942 - accuracy: 0.1690\n","Epoch 6/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.2436 - accuracy: 0.1817\n","Epoch 7/100\n","87/87 [==============================] - 3s 36ms/step - loss: 3.1240 - accuracy: 0.2157\n","Epoch 8/100\n","87/87 [==============================] - 3s 37ms/step - loss: 3.0427 - accuracy: 0.2290\n","Epoch 9/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.9285 - accuracy: 0.2584\n","Epoch 10/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.7998 - accuracy: 0.2884\n","Epoch 11/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.6918 - accuracy: 0.3005\n","Epoch 12/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.6280 - accuracy: 0.3247\n","Epoch 13/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.5069 - accuracy: 0.3391\n","Epoch 14/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.4235 - accuracy: 0.3651\n","Epoch 15/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.3547 - accuracy: 0.3800\n","Epoch 16/100\n","87/87 [==============================] - 3s 37ms/step - loss: 2.2301 - accuracy: 0.4152\n","Epoch 17/100\n","87/87 [==============================] - 3s 37ms/step - loss: 2.1499 - accuracy: 0.4245\n","Epoch 18/100\n","87/87 [==============================] - 3s 36ms/step - loss: 2.0844 - accuracy: 0.4481\n","Epoch 19/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.9509 - accuracy: 0.4723\n","Epoch 20/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.9167 - accuracy: 0.4821\n","Epoch 21/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7998 - accuracy: 0.5231\n","Epoch 22/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.7195 - accuracy: 0.5277\n","Epoch 23/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.6468 - accuracy: 0.5594\n","Epoch 24/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.5921 - accuracy: 0.5582\n","Epoch 25/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.5055 - accuracy: 0.5934\n","Epoch 26/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.4204 - accuracy: 0.6096\n","Epoch 27/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.3360 - accuracy: 0.6269\n","Epoch 28/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.2632 - accuracy: 0.6442\n","Epoch 29/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.1989 - accuracy: 0.6632\n","Epoch 30/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.1231 - accuracy: 0.6857\n","Epoch 31/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.0716 - accuracy: 0.6920\n","Epoch 32/100\n","87/87 [==============================] - 3s 36ms/step - loss: 1.0328 - accuracy: 0.7030\n","Epoch 33/100\n","87/87 [==============================] - 3s 37ms/step - loss: 1.0244 - accuracy: 0.7140\n","Epoch 34/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.9450 - accuracy: 0.7209\n","Epoch 35/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.8537 - accuracy: 0.7664\n","Epoch 36/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.7188 - accuracy: 0.8045\n","Epoch 37/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.8102 - accuracy: 0.7601\n","Epoch 38/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6925 - accuracy: 0.7907\n","Epoch 39/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.7135 - accuracy: 0.8022\n","Epoch 40/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.6124 - accuracy: 0.8276\n","Epoch 41/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5761 - accuracy: 0.8408\n","Epoch 42/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5981 - accuracy: 0.8356\n","Epoch 43/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.5361 - accuracy: 0.8547\n","Epoch 44/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.5203 - accuracy: 0.8587\n","Epoch 45/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4553 - accuracy: 0.8720\n","Epoch 46/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4656 - accuracy: 0.8639\n","Epoch 47/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.4201 - accuracy: 0.8800\n","Epoch 48/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3665 - accuracy: 0.8985\n","Epoch 49/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3342 - accuracy: 0.9048\n","Epoch 50/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3257 - accuracy: 0.9100\n","Epoch 51/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3390 - accuracy: 0.9066\n","Epoch 52/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2937 - accuracy: 0.9123\n","Epoch 53/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.3020 - accuracy: 0.9152\n","Epoch 54/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2746 - accuracy: 0.9216\n","Epoch 55/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2511 - accuracy: 0.9319\n","Epoch 56/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2482 - accuracy: 0.9296\n","Epoch 57/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2396 - accuracy: 0.9343\n","Epoch 58/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.2430 - accuracy: 0.9302\n","Epoch 59/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2606 - accuracy: 0.9198\n","Epoch 60/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.2159 - accuracy: 0.9412\n","Epoch 61/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.2222 - accuracy: 0.9435\n","Epoch 62/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1993 - accuracy: 0.9469\n","Epoch 63/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1742 - accuracy: 0.9510\n","Epoch 64/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1513 - accuracy: 0.9660\n","Epoch 65/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1247 - accuracy: 0.9689\n","Epoch 66/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1360 - accuracy: 0.9666\n","Epoch 67/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1467 - accuracy: 0.9567\n","Epoch 68/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1236 - accuracy: 0.9706\n","Epoch 69/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1319 - accuracy: 0.9689\n","Epoch 70/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1317 - accuracy: 0.9666\n","Epoch 71/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1425 - accuracy: 0.9625\n","Epoch 72/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1045 - accuracy: 0.9689\n","Epoch 73/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1352 - accuracy: 0.9642\n","Epoch 74/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1129 - accuracy: 0.9683\n","Epoch 75/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.1293 - accuracy: 0.9694\n","Epoch 76/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0969 - accuracy: 0.9764\n","Epoch 77/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0637 - accuracy: 0.9908\n","Epoch 78/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0952 - accuracy: 0.9758\n","Epoch 79/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0901 - accuracy: 0.9781\n","Epoch 80/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0997 - accuracy: 0.9740\n","Epoch 81/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0836 - accuracy: 0.9804\n","Epoch 82/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0727 - accuracy: 0.9827\n","Epoch 83/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0786 - accuracy: 0.9815\n","Epoch 84/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0639 - accuracy: 0.9862\n","Epoch 85/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0849 - accuracy: 0.9758\n","Epoch 86/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0722 - accuracy: 0.9833\n","Epoch 87/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0767 - accuracy: 0.9844\n","Epoch 88/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0644 - accuracy: 0.9867\n","Epoch 89/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0462 - accuracy: 0.9896\n","Epoch 90/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0790 - accuracy: 0.9810\n","Epoch 91/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0782 - accuracy: 0.9804\n","Epoch 92/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0513 - accuracy: 0.9925\n","Epoch 93/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0630 - accuracy: 0.9827\n","Epoch 94/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0854 - accuracy: 0.9764\n","Epoch 95/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0576 - accuracy: 0.9867\n","Epoch 96/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0591 - accuracy: 0.9862\n","Epoch 97/100\n","87/87 [==============================] - 3s 37ms/step - loss: 0.0602 - accuracy: 0.9862\n","Epoch 98/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0423 - accuracy: 0.9902\n","Epoch 99/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0434 - accuracy: 0.9908\n","Epoch 100/100\n","87/87 [==============================] - 3s 36ms/step - loss: 0.0480 - accuracy: 0.9897\n"]}],"source":["maxIt = 100\n","batch_size_total = 20\n","shifts = .05\n","aug = ImageDataGenerator(width_shift_range = shifts, height_shift_range = shifts, fill_mode=\"nearest\")\n","def polynomial_decay(epoch):\n","    maxEpochs = numberOfEpochs\n","    baseLearningRate = .01\n","    power = 1.0\n","    \n","    alpha = baseLearningRate * (1 - (epoch / float(numberOfEpochs))) ** power\n","    \n","    # return the learning rate\n","    return alpha\n","\n","\n","callbacks = [LearningRateScheduler(polynomial_decay)]\n","\n","opt = SGD(learning_rate = best_learning_rate, momentum=best_momentum)\n","model = MiniGoogLeNet.build(width = 64, height = 64, depth = 3, classes = 51)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics=[\"accuracy\"])\n","\n","H = model.fit(aug.flow(trainX, trainY, batch_size = batch_size_total), steps_per_epoch=len(trainX) // batch_size_total, epochs = maxIt, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"hRmORFW_9UXm"},"source":["### This is our best performing model"]},{"cell_type":"markdown","metadata":{"id":"Sn-gwv0eelP2"},"source":["# Final Test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":964,"status":"ok","timestamp":1637036046440,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"aa3qzl3goAez","outputId":"f40a2f2b-dd72-4480-b77d-008a11472f75"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Test accuracy\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.29      0.36         7\n","           1       1.00      0.50      0.67        12\n","           2       0.17      0.10      0.12        10\n","           3       1.00      0.67      0.80        12\n","           4       0.33      0.40      0.36         5\n","           5       0.50      0.33      0.40        12\n","           6       0.40      0.50      0.44         8\n","           7       0.55      0.50      0.52        12\n","           8       0.60      0.46      0.52        13\n","           9       0.75      0.60      0.67        10\n","          10       0.67      0.67      0.67         6\n","          11       0.75      0.64      0.69        14\n","          12       0.33      0.29      0.31         7\n","          13       0.71      1.00      0.83         5\n","          14       0.50      0.50      0.50         8\n","          15       0.27      0.38      0.32         8\n","          16       0.27      0.38      0.32         8\n","          17       0.27      0.60      0.37         5\n","          18       0.50      0.43      0.46        14\n","          19       0.14      0.22      0.17         9\n","          20       0.55      0.67      0.60         9\n","          21       0.50      0.20      0.29        10\n","          22       0.43      0.86      0.57         7\n","          23       0.25      0.40      0.31         5\n","          24       0.20      0.50      0.29         2\n","          25       0.17      0.20      0.18         5\n","          26       0.14      0.14      0.14         7\n","          27       0.83      0.83      0.83        12\n","          28       0.40      0.67      0.50         6\n","          29       0.30      0.43      0.35         7\n","          30       0.45      0.38      0.42        13\n","          31       0.62      0.31      0.42        16\n","          32       0.00      0.00      0.00         9\n","          33       0.45      0.42      0.43        12\n","          34       0.30      0.50      0.37         6\n","          35       0.00      0.00      0.00         9\n","          36       0.57      0.80      0.67         5\n","          37       0.67      0.44      0.53         9\n","          38       1.00      0.33      0.50         9\n","          39       0.00      0.00      0.00         5\n","          40       0.31      0.42      0.36        12\n","          41       0.50      0.29      0.36         7\n","          42       0.75      0.86      0.80         7\n","          43       0.24      0.60      0.34        10\n","          44       0.38      1.00      0.55         3\n","          45       0.62      0.83      0.71         6\n","          46       1.00      0.80      0.89         5\n","          47       0.64      0.58      0.61        12\n","          48       0.54      0.64      0.58        11\n","          49       0.36      0.33      0.35        12\n","          50       0.50      0.67      0.57         6\n","\n","    accuracy                           0.46       439\n","   macro avg       0.47      0.48      0.45       439\n","weighted avg       0.50      0.46      0.46       439\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7f3f9674c610>"]},"execution_count":70,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["print('\\n Test accuracy')\n","predictedY = model.predict(testX)\n","predictedY = predictedY.argmax(axis=1)\n","# CHANGE OTHER BACK\n","other = testY.argmax(axis=1)\n","print(classification_report(other, predictedY))\n","\n","# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, maxIt), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, maxIt), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":756,"status":"ok","timestamp":1637036054999,"user":{"displayName":"CodeBlue1919","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFgnip1NCor7z2WPEEajH7L4-39z1xGiaP0W2p=s64","userId":"09499638321677918214"},"user_tz":300},"id":"KTIcYTJQpMKj","outputId":"d9fcd9db-da90-4d32-e782-6e694252ca58"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Testing Confusion Matrix:\n","\n"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"execution_count":71,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from seaborn import heatmap\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","import matplotlib.pyplot as plt\n","\n","\n","# predict the labels of the test set\n","predictedY = model.predict(testX)\n","\n","print('\\nTesting Confusion Matrix:\\n')\n","predictedY = predictedY.argmax(axis = 1)\n","other = testY.argmax(axis = 1)\n","heatmap(confusion_matrix(other, predictedY))\n","plt.figure()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RvwLlRMf8dL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"project2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
